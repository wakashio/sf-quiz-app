number,question,choiceA,choiceB,choiceC,choiceD,correct_answer,explanation
2,Salesforceのエコシステムにおいて、Data Cloudは顧客データを統合し、インサイトを生成する中心的な役割を担います。Marketing Cloud Engagementが主に顧客とのコミュニケーション実行（メール送信、ジャーニー実行など）を担うのに対し、Data Cloudが提供する主要な価値として最も適切なものはどれでしょうか？,Eメールテンプレートの作成とA/Bテスト機能,複数のソースからの顧客データを統合し、統一プロファイルを作成する機能,Webサイトやランディングページの作成機能,リードスコアリングと営業担当への自動割り当て機能,B,"A. Eメールテンプレートの作成とA/Bテスト機能 - これは、Eメールマーケティングキャンペーンを実行するためのMarketing Cloud Engagementなどのマーケティングオートメーションツールが提供する典型的な機能です。Data Cloudの主要な価値ではありません。

B. 複数のソースからの顧客データを統合し、統一プロファイルを作成する機能 - 正解です。Data Cloud（Customer Data Platform）の最も基本的な価値は、CRM、マーケティングツール、Eコマースサイト、サービス履歴など、企業内外のサイロ化されたデータソースから顧客データを集約し、アイデンティティ解決を通じて顧客一人ひとりの統一されたプロファイル（単一顧客ビュー）を構築することにあります。

C. Webサイトやランディングページの作成機能 - Webサイトやランディングページの作成は、Experience CloudやMarketing Cloud EngagementのWeb Studioなどの機能によって提供されます。Data Cloudの機能ではありません。

D. リードスコアリングと営業担当への自動割り当て機能 - リード（見込み顧客）のスコアリングや営業への割り当ては、主にMarketing Cloud Account Engagement（旧Pardot）やSales Cloudのリード管理機能が担います。Data Cloudで生成されたインサイトをこれらのプロセスで活用することは可能ですが、機能自体を提供するわけではありません。"
3,Data Cloudのアイデンティティ解決プロセスでは、マッチルールによって同一人物と特定された複数のソースレコードから、統合プロファイルにどのデータソースのどの項目値を採用するかを決定する必要があります。例えば、メールアドレスについてCRMの情報とWeb会員登録の情報がある場合、どちらを優先するかを定義するルールは何と呼ばれますか？,調整ルール,マッチルール,データストリームルール,セグメンテーションルール,A,"A. 調整ルール - 正解です。調整ルールは、アイデンティティ解決プロセスにおいて、複数のソースレコードに同じ項目（例：メールアドレス、電話番号）が存在し、その値が異なる場合に、どのデータソースの値を統合プロファイルの該当項目値として採用するかを決定するためのルールセットです。優先順位付けのロジック（例：最後に更新された値を優先、特定のデータソースを優先など）を定義します。

B. マッチルール - マッチルールは、異なるデータソースから取り込まれたレコードが、同じ個人や組織を表しているかどうかを識別するための基準（例：メールアドレスの完全一致、氏名と郵便番号の組み合わせ一致など）を定義するルールです。どの値を採用するかの優先順位を決めるものではありません。

C. データストリームルール - データストリームに関連するルールは、通常、データの取り込み頻度、フィルタリング、初期的な変換などを指します。統合プロファイルの項目値の優先順位付けを行うものではありません。

D. セグメンテーションルール - セグメンテーションルールは、統合された顧客プロファイルの中から、特定のマーケティングキャンペーンや分析の対象となる顧客グループを抽出するための条件を定義するルールです。"
4,Data Cloudに様々なソースからデータを取り込む際、データの品質を確保し、後続のアイデンティティ解決や分析の精度を高めることが重要です。データ取り込みプロセスにおいて、データ品質を維持・向上させるためにコンサルタントが考慮すべき点や利用できる機能として適切なものはどれでしょうか？（２つ選択）,アイデンティティ解決のマッチルールを可能な限り緩く設定する。,Data Cloudの数式（Formula）機能を利用してデータ形式を標準化する。,取り込み対象から欠損値や異常値が多い項目を除外することを検討する。,取り込むデータ項目のデータ型（テキスト、数値、日付など）を適切に定義する。,"B,D","A. アイデンティティ解決のマッチルールを可能な限り緩く設定する。 - マッチルールを緩く設定しすぎると、本来は異なる個人を示すレコードが誤って統合されてしまうリスクが高まり、統合プロファイルのデータ品質を低下させる可能性があります。適切なバランスが必要です。

B. Data Cloudの数式（Formula）機能を利用してデータ形式を標準化する。 - 正解です。データストリームのデータマッピングプロセスでは、数式フィールドを作成して、取り込むデータの値を変換したり、形式を統一したり（例：日付形式の標準化、空白の除去、大文字/小文字の統一）することができます。これはデータの一貫性を高め、品質を向上させる有効な手段です。

C. 取り込み対象から欠損値や異常値が多い項目を除外することを検討する。 - データ品質が極端に低い項目を取り込まないという選択肢もありますが、可能な限りデータを活用するためには、取り込んだ上でクレンジングや補完を行う方が望ましい場合もあります。品質を「維持・向上させる」積極的な手段とは言い切れない場合があります。

D. 取り込むデータ項目のデータ型（テキスト、数値、日付など）を適切に定義する。 - 正解です。データソースオブジェクト（DSO）およびデータモデルオブジェクト（DMO）で項目を定義する際に、そのデータの内容に合った適切なデータ型（テキスト、数値、日付、日時、真偽値など）を選択することは、データの整合性を保証し、後続の計算や分析でエラーを防ぐための基本的なデータ品質管理プラクティスです。"
5,Data Cloudは、CRMデータ、行動データ、トランザクションデータなど、様々な種類の顧客データを統合できます。顧客が自らの意思で、アンケート回答やプロファイル更新、プリファレンス設定などを通じて企業に直接提供するデータのことを、一般的に何と呼びますか？,ファーストパーティデータ,セカンドパーティデータ,ゼロパーティデータ,サードパーティデータ,C,"A. ファーストパーティデータ - ファーストパーティデータは、企業が顧客との直接的なやり取り（例：自社ウェブサイトでの行動、CRM内の情報、購入履歴）を通じて収集するデータです。顧客が自発的に提供するゼロパーティデータとは区別されます。

B. セカンドパーティデータ - セカンドパーティデータは、信頼できる他の企業が収集したファーストパーティデータを、パートナーシップや直接的な契約を通じて取得したデータです。

C. ゼロパーティデータ - 正解です。ゼロパーティデータは、顧客が意図的かつ自発的に企業に対して直接提供するデータです。これには、アンケートへの回答、設定した好み（プリファレンス）、プロファイル情報などが含まれ、顧客の明確な意図や関心を反映しています。

D. サードパーティデータ - サードパーティデータは、そのデータを直接収集した企業以外（データアグリゲーターなど）から購入される、複数のソースから集められた大規模なデータセットです。通常、顧客と企業との間に直接的な関係はありません。"
6,Universal Containersは、Data Cloudで特定条件を満たした顧客（例：計算済みインサイトで「解約リスク高」と判定された顧客）に対して、自動的にSalesforce Sales Cloud上でフォローアップのToDoを作成したり、Service Cloudで優先度の高いケースを作成したりするような、プロアクティブなアクションを実行したいと考えています。Data Cloudのデータを起点として、他のSalesforceアプリケーションでこのような自動化プロセスを起動するために利用できる主なメカニズムは何でしょうか？（２つ選択）,Data Cloudトリガーによるフロー起動,ApexトリガーをData Cloudオブジェクトに直接設定,Data Cloudデータを活用したジャーニービルダー連携（Marketing Cloud Engagement）,Data Cloudからの手動データエクスポートとインポート,"A,C","A. Data Cloudトリガーによるフロー起動 - 正解です。Data Cloudでは、特定のイベント（例：セグメントへのメンバー追加、計算済みインサイトの値が閾値を超える）をトリガーとして、Salesforce Platformのフローを自動的に起動する設定が可能です。このフロー内で、ToDoの作成、ケースの作成、カスタム通知の送信など、様々な自動化アクションを実行できます。

B. ApexトリガーをData Cloudオブジェクトに直接設定 - Data Cloudが内部で使用するオブジェクトに対して、標準のSalesforceオブジェクトと同様に直接Apexトリガーを作成・設定することは、一般的にはサポートされておらず、推奨される実装方法ではありません。自動化にはフロー連携などを利用します。

C. Data Cloudデータを活用したジャーニービルダー連携（Marketing Cloud Engagement） - 正解です。Data Cloudで作成したセグメントやインサイトをMarketing Cloud Engagementのジャーニーのエントリーソースとして使用できます。ジャーニービルダー内のステップとして、メール送信だけでなく、SalesforceのToDo作成やケース作成などのアクティビティを実行させることが可能です。

D. Data Cloudからの手動データエクスポートとインポート - データを手動でエクスポートし、他のシステムにインポートする方法では、リアルタイム性や自動化の要件を満たすことができません。これはプロアクティブな自動アクションを実行するためのメカニズムではありません。"
7,Data Cloudにデータを取り込む際、データソースの種類や連携方法に応じて適切なデータストリームタイプを選択する必要があります。Amazon S3バケットに定期的にアップロードされるCSVファイルからバッチでデータを取り込みたい場合、コンサルタントはどのデータストリームタイプを選択することを推奨すべきでしょうか？,Salesforce CRM,Web and Mobile Application,Ingestion API,Cloud Storage,D,"A. Salesforce CRM - このデータストリームタイプは、Salesforce Sales CloudやService Cloudなど、同じSalesforce Platform上の組織からデータを取り込むために使用されます。Amazon S3からのファイル取り込みには適していません。

B. Web and Mobile Application - このデータストリームタイプは、Webサイトやモバイルアプリケーションに組み込んだSDKを通じて、ユーザーの行動イベントなどをリアルタイムに近い形で収集するために使用されます。S3からのバッチファイル取り込みには使用されません。

C. Ingestion API - Ingestion APIデータストリームは、APIコールを通じて外部システムからプログラム的にデータをData Cloudに送信する場合に使用されます。S3バケットからファイルを定期的に読み込む用途には通常、Cloud Storageタイプがより適しています。

D. Cloud Storage - 正解です。Cloud Storageデータストリームタイプは、Amazon S3、Google Cloud Storage (GCS)、Microsoft Azure Blob Storageなどの外部クラウドストレージに配置されたデータファイル（CSV形式やParquet形式など）を検出し、スケジュールに基づいてバッチ処理でData Cloudに取り込むために設計されています。"
8,Universal Containersは、Data Cloudで「毎週日曜日の夜間に最新のデータに基づいて更新される、ロイヤル顧客セグメント」を作成し、その結果をMarketing Cloud Engagementに連携したいと考えています。セグメントのメンバーシップを定期的に再計算し、最新の状態をアクティベーションターゲットに反映させるためには、どの設定を行う必要がありますか？,アイデンティティ解決の実行スケジュール,セグメントの公開スケジュール,データストリームの更新スケジュール,計算済みインサイトの更新スケジュール,B,"A. アイデンティティ解決の実行スケジュール - アイデンティティ解決のスケジュールは、データソースから取り込まれたレコードを統合プロファイルにまとめるプロセスの実行頻度を定義します。セグメントのメンバーシップを計算し公開するスケジュールとは異なります。

B. セグメントの公開スケジュール - 正解です。セグメントを作成した後、そのセグメントの定義に基づいて対象となる顧客プロファイルを評価し、結果を利用可能にするプロセスを「公開（Publish）」と呼びます。この公開処理を定期的に（例：毎日、毎週日曜日など）実行するようにスケジュールを設定することで、セグメントのメンバーシップを最新の状態に保ち、アクティベーションターゲットで利用できるようになります。

C. データストリームの更新スケジュール - データストリームの更新スケジュールは、外部のデータソースからData Cloudへ新しいデータや更新されたデータを取り込む頻度を定義します。セグメントの計算・公開スケジュールとは直接異なります。

D. 計算済みインサイトの更新スケジュール - 計算済みインサイトの更新スケジュールは、定義された計算ロジックに基づいてインサイトの値を再計算する頻度を定義します。セグメントの条件に計算済みインサイトが含まれている場合、このスケジュールも関連しますが、セグメント自体の公開スケジュールとは別の設定です。"
9,Data Cloudのアイデンティティ解決プロセスが完了すると、複数のソースシステムからの顧客データが統合され、顧客一人ひとりを表す単一のレコードが生成されます。この統合された顧客レコードはData Cloud内で何と呼ばれますか？,統合個人プロファイル (Unified Individual Profile),データソースオブジェクト (DSO),アクティベーションターゲット,データレイクハウス (Data Lakehouse),A,"A. 統合個人プロファイル (Unified Individual Profile) - 正解です。アイデンティティ解決プロセスは、様々なデータソースから得られた、同一人物に関連すると思われる複数のレコードを照合・統合し、その結果として「統合個人プロファイル」を作成します。これは、その顧客に関する情報を集約した、単一の包括的なレコードです。

B. データソースオブジェクト (DSO) - DSOは、データストリームを通じて各データソースから取り込まれたデータを、元のスキーマに近い形で保持するオブジェクトです。アイデンティティ解決によって統合された結果のレコードではありません。

C. アクティベーションターゲット - アクティベーションターゲットは、Data Cloudで作成されたセグメントやインサイトを送信する対象となる外部システム（例：Marketing Cloud Engagement）や場所（例：S3バケット）を定義するものです。顧客レコードそのものではありません。

D. データレイクハウス (Data Lakehouse) - データレイクハウスは、Data Cloudが採用しているデータ管理アーキテクチャの概念であり、構造化データと非構造化データの両方を柔軟に格納・分析できる特徴を持ちます。統合された顧客レコード自体を指す用語ではありません。"
10,Universal Containersは、Data Cloudで作成した顧客セグメントのサイズ推移や、計算済みインサイト（例：顧客LTV）の分布状況などを分析し、ダッシュボードで可視化したいと考えています。Data Cloudのデータを利用してこれらの分析や可視化を行うための主な方法として、適切なものを2つ選択してください。（２つ選択）,データストリーム設定画面で分析グラフを確認する。,アクティベーションを設定して外部BIツールにデータを送信する。,CRM Analytics（旧Tableau CRM）を活用してData Cloudデータを分析・可視化する。,Tableauを使用してData Cloudに接続し、高度な分析やダッシュボードを作成する。,"C,D","A. データストリーム設定画面で分析グラフを確認する。 - データストリーム画面では、データの取り込み状況やエラーなどを確認できますが、セグメントサイズの推移や計算済みインサイトの詳細な分布状況を分析・可視化する機能は提供されていません。

B. アクティベーションを設定して外部BIツールにデータを送信する。 - アクティベーションは主にセグメントのメンバーリストなどを外部システムに連携させるための機能です。分析に必要な詳細なデータを外部BIツールに送る一般的な方法ではなく、他の連携手段（例：Tableau接続、データ共有）が推奨されることが多いです。

C. CRM Analytics（旧Tableau CRM）を活用してData Cloudデータを分析・可視化する。 - 正解です。CRM AnalyticsはSalesforceプラットフォーム上で動作する高度な分析ツールであり、Data Cloudのデータモデルオブジェクト（DMO）や計算済みインサイトオブジェクト（CIO）に接続してデータを取得し、複雑なデータ分析やインタラクティブなダッシュボードを作成することができます。

D. Tableauを使用してData Cloudに接続し、高度な分析やダッシュボードを作成する。 - 正解です。TableauはData Cloudへの専用コネクタを提供しており、Tableau DesktopやTableau CloudからData Cloudのデータに直接接続できます。これにより、Data Cloudの統合されたデータを活用して、高度なビジュアル分析やカスタムダッシュボードの作成が可能になります。

ここから先は有料部分です"
11,Data Cloudのデータモデリングでは、取り込んだデータを意味のあるカテゴリに分類します。顧客のWebサイト訪問履歴、メールの開封・クリック、モバイルアプリの利用状況など、顧客が企業とどのように関わっているかを示すインタラクションデータは、主にどのデータモデルカテゴリに分類されますか？,プロファイルデータ (Profile Data),エンゲージメントデータ (Engagement Data),その他データ (Other Data),データソースデータ (Data Source Data),B,"A. プロファイルデータ (Profile Data) - プロファイルデータカテゴリには、顧客の氏名、連絡先情報、住所、生年月日など、顧客自身を説明する比較的静的な属性情報が含まれます。顧客の行動やインタラクションデータは通常ここには分類されません。

B. エンゲージメントデータ (Engagement Data) - 正解です。エンゲージメントデータカテゴリは、顧客が企業やブランドとどのように関与・対話したかを示す時間ベースの行動データを格納します。具体的には、Webサイトの閲覧履歴、Eメールの開封やクリック、モバイルアプリの利用ログ、ソーシャルメディアでの「いいね」やコメントなどが含まれます。

C. その他データ (Other Data) - その他データカテゴリは、プロファイルデータやエンゲージメントデータ以外の、コンテキスト情報や参照情報として利用されるデータを格納します。例えば、製品カタログ情報、店舗の所在地リスト、外部の気象データなどが該当します。

D. データソースデータ (Data Source Data) - データソースデータという公式なデータモデルカテゴリはありません。Data Cloudではデータソースオブジェクト(DSO)がデータソースからの生のデータを保持しますが、これはモデリングにおけるカテゴリ分類とは異なります。"
12,Data Cloudコンサルタントが、Salesforce CRMコネクタを使用して設定されたデータストリームの稼働状況を確認しています。データストリームの管理画面で、コンサルタントがデータ取り込みの成功・失敗状況や、処理されたレコード数などを監視するために参照すべき主要なタブまたはセクションは何でしょうか？,データマッピング,項目リスト,設定,処理履歴 (Processing History),D,"A. データマッピング - データマッピングセクションでは、データソースオブジェクト（DSO）の項目とデータモデルオブジェクト（DMO）の項目との対応付けを定義・確認しますが、データ取り込み処理の実行結果や履歴は表示されません。

B. 項目リスト - 項目リストセクションでは、このデータストリームで取り込まれるデータソースの項目とそのデータ型などを確認できますが、処理の成功・失敗やレコード数といった実行履歴に関する情報は含まれません。

C. 設定 - 設定セクションでは、データストリームの名前、説明、接続されているデータソース、取り込みスケジュールなどの基本的な構成情報を確認・編集できますが、個々の実行結果の詳細は表示されません。

D. 処理履歴 (Processing History) - 正解です。処理履歴タブ（またはセクション）には、データストリームが実行された各回のログが表示されます。ここを参照することで、各実行のステータス（成功、失敗、処理中など）、開始時刻、終了時刻、処理されたレコード数、エラーが発生した場合はその詳細などを確認でき、データ取り込みの稼働状況を正確に監視することができます。"
13,Data Cloudは、顧客データを統合し、リアルタイムに近いインサイトを提供することに重点を置いていますが、従来のデータウェアハウス(DWH)とは異なる特徴も持っています。Data Cloudが従来のDWHと比較して持つ主な特徴や利点として、最も適切な説明はどれでしょうか？,構造化データのみを扱うことに特化している点。,主に過去のバッチ処理分析に最適化されている点。,リアルタイムの顧客行動データを取り込み、統合プロファイルを迅速に更新できる点。,データ変換や加工を行わず、生のデータをそのまま格納する点。,C,"A. 構造化データのみを扱うことに特化している点。 - Data Cloudは、CRMのような構造化データに加え、Webサイトやモバイルアプリからのイベントデータなど、半構造化データも効率的に取り込み、活用できるように設計されています。構造化データのみに特化しているわけではありません。

B. 主に過去のバッチ処理分析に最適化されている点。 - 従来のデータウェアハウス(DWH)はバッチ処理による過去データの分析に重点を置くことが多いですが、Data Cloudはバッチ処理に加えて、ストリーミングデータの取り込みやリアルタイムに近いデータ更新・インサイト生成を可能にすることを目指しています。

C. リアルタイムの顧客行動データを取り込み、統合プロファイルを迅速に更新できる点。 - 正解です。Data Cloudは、Webサイトやモバイルアプリからのクリックストリームデータなどの顧客行動データをリアルタイムに近い形で取り込み、それらの情報に基づいて統合プロファイルやセグメントを迅速に更新できる能力を持っています。これは、変化する顧客の状態に素早く対応する上で、従来のバッチ処理中心のDWHに対する大きな利点となります。

D. データ変換や加工を行わず、生のデータをそのまま格納する点。 - Data Cloudはデータレイクハウスのアーキテクチャを採用しており、生のデータを格納する能力も持ちますが、同時にデータモデリング（DSOからDMOへのマッピング）や計算済みインサイト作成などの過程で、データの変換、正規化、集計といった加工処理も行います。生のデータをそのまま格納するだけではありません。"
14,Universal Containersは、Data Cloudで作成したセグメント情報や計算済みインサイトを、Salesforceの標準レポートやApex、フローなどで直接利用したいと考えています。Data CloudのデータをSalesforce Platform上の他の機能から直接クエリできるようにするための主要なメカニズムは何でしょうか？,データ共有（Data Share）,データストリーム,アクティベーション,コネクテッドアプリケーション,A,"A. データ共有（Data Share） - 正解です。データ共有は、Data Cloudで作成されたデータモデルオブジェクト（DMO）や計算済みインサイトオブジェクト（CIO）を、Salesforce Platform上の他の標準機能（レポート、ダッシュボード、フロー、Apexなど）から直接クエリできるようにする機能です。これにより、データをコピーすることなく、Data CloudのインサイトをSalesforceの業務プロセスでシームレスに活用できます。

B. データストリーム - データストリームは、外部データソースからData Cloudへデータをインポートするための仕組みであり、Data CloudからSalesforce Platformの他の機能へデータを共有するものではありません。

C. アクティベーション - アクティベーションは、Data Cloudで作成したセグメントやインサイトを、Marketing Cloud Engagementなどの連携アプリケーションや外部プラットフォームへ送信（プッシュ）するためのプロセスです。Salesforce Platform内で直接データをクエリするための機能ではありません。

D. コネクテッドアプリケーション - コネクテッドアプリケーションは、外部アプリケーションがSalesforce APIを使用してSalesforce組織に安全に接続するためのフレームワークです。Data CloudのデータをPlatform内で共有する機能とは目的が異なります。"
15,Data Cloudでアイデンティティ解決ルールセットを実行した後、その結果がビジネス要件に対してどの程度正確であるかを評価することが重要です。例えば、「異なる個人が誤って同じプロファイルに統合されていないか」や「同じ個人が複数の異なるプロファイルに分割されていないか」を評価するための指標は、総称して何と呼ばれますか？,データ取り込み成功率,セグメント到達率,アイデンティティ解決精度指標 (Identity Resolution Accuracy Metrics),アクティベーションエラー率,C,"A. データ取り込み成功率 - データ取り込み成功率は、データストリームがデータソースからData Cloudへデータを正常に取り込めた割合を示す指標です。アイデンティティ解決プロセス自体の精度を評価するものではありません。

B. セグメント到達率 - セグメント到達率は、アクティベーションを通じて連携されたセグメントメンバーに対して、実際にマーケティングメッセージなどが到達した割合を示す指標であり、アイデンティティ解決の精度を測るものではありません。

C. アイデンティティ解決精度指標 (Identity Resolution Accuracy Metrics) - 正解です。アイデンティティ解決の精度指標は、設定されたマッチルールや調整ルールがどの程度正確に顧客プロファイルを統合・分離できているかを評価するための指標群を指します。これには、過剰な統合（False Positives）や統合漏れ（False Negatives）の発生率などが含まれ、ルールの見直しや改善に役立てられます。

D. アクティベーションエラー率 - アクティベーションエラー率は、Data Cloudから外部システムへデータを送信するアクティベーションプロセス中に発生したエラーの割合を示す指標です。アイデンティティ解決の精度とは直接関係ありません。"
16,Data Cloudには、顧客のプライバシー保護やGDPRなどの規制遵守を支援する機能が含まれています。顧客から自身の個人データの削除要求があった場合、Data Cloudコンサルタントはその要求に対応するために、Data Cloud内のどの機能を主に利用することを推奨すべきでしょうか？,データストリームの停止,アイデンティティ解決の再実行,セグメントの再公開,同意管理フレームワークのデータ削除機能,D,"A. データストリームの停止 - データストリームを停止すると、そのソースからの新しいデータの取り込みが止まりますが、既にData Cloud内に格納されている既存の顧客データが削除されるわけではありません。

B. アイデンティティ解決の再実行 - アイデンティティ解決は、異なるソースのレコードを照合して統合プロファイルを作成・更新するプロセスです。特定の顧客データを削除する機能ではありません。

C. セグメントの再公開 - セグメントの再公開は、セグメントの条件に基づいて最新のメンバーシップを計算し、アクティベーションターゲットで利用可能にするプロセスです。データ削除要求に対応する機能ではありません。

D. 同意管理フレームワークのデータ削除機能 - 正解です。Data Cloudは、顧客の同意やプライバシー設定を管理するためのフレームワークを提供しています。このフレームワークには、顧客からのデータ削除要求（忘れられる権利など）を受け付け、関連する統合プロファイルやソースレコードを特定し、Data Cloud内からデータを削除するプロセスを支援する機能が含まれています。"
17,Data Cloudを導入し、様々な顧客データを統合・分析することによって、企業が得られる主なビジネス上の利点として適切なものを2つ選択してください。（２つ選択）,よりパーソナライズされた顧客体験を提供できるようになる。,顧客インサイトに基づいた効果的なマーケティングセグメントを作成できる。,企業のサプライチェーン管理プロセスを直接的に自動化できる。,会計監査に必要な財務レポートを自動生成できる。,"A,B","A. よりパーソナライズされた顧客体験を提供できるようになる。 - 正解です。Data Cloudによって構築された統合顧客プロファイルは、顧客の属性、行動履歴、好みなどを包括的に理解することを可能にします。この深い理解に基づいて、Webサイト、メール、広告、サービス応対など、あらゆるタッチポイントで顧客一人ひとりに最適化された、よりパーソナルな体験を提供できます。

B. 顧客インサイトに基づいた効果的なマーケティングセグメントを作成できる。 - 正解です。Data Cloudは、単なる属性だけでなく、計算済みインサイト（例：LTVスコア、エンゲージメントレベル）やリアルタイムの行動データも活用して、より精度の高いマーケティングセグメントを作成できます。これにより、キャンペーンのターゲティング精度が向上し、マーケティング投資対効果（ROI）の改善につながります。

C. 企業のサプライチェーン管理プロセスを直接的に自動化できる。 - Data Cloudは顧客データプラットフォーム（CDP）であり、在庫管理、物流、生産計画といったサプライチェーン管理（SCM）の業務プロセスを直接的に自動化する機能は提供していません。

D. 会計監査に必要な財務レポートを自動生成できる。 - Data Cloudは顧客に関するデータの管理・分析に特化しており、企業の会計処理や財務諸表の作成、監査対応といった財務会計領域の機能を提供するものではありません。"
18,Data Cloudのデータストリームを設定する際、データソースからのデータの取り込み方法を決定する必要があります。データソースの全データを毎回洗い替えするのではなく、最後の取り込み以降に変更または追加されたデータのみを取り込む方法を指す用語は何でしょうか？,フルリフレッシュ (Full Refresh),ストリーミング取り込み (Streaming Ingestion),増分更新 (Incremental Refresh),データマッピング (Data Mapping),C,"A. フルリフレッシュ (Full Refresh) - フルリフレッシュは、データストリームの実行時に、データソースから指定された範囲のデータを毎回すべて取得し直し、Data Cloud内の対応するデータを置き換える更新方法です。

B. ストリーミング取り込み (Streaming Ingestion) - ストリーミング取り込みは、Ingestion APIやWeb/Mobile SDKなどを利用して、データが発生するたびにほぼリアルタイムでData Cloudに送信・取り込む方式を指します。バッチ処理における更新方法とは異なります。

C. 増分更新 (Incremental Refresh) - 正解です。増分更新は、データストリームの実行時に、前回の実行以降に変更が加えられたレコードや新しく追加されたレコードのみをデータソースから抽出し、Data Cloudに取り込む更新方法です。これにより、毎回全データを処理するフルリフレッシュに比べて、処理時間とリソース消費を抑えることができます。

D. データマッピング (Data Mapping) - データマッピングは、データソースオブジェクト（DSO）の項目を、Data Cloudの標準またはカスタムのデータモデルオブジェクト（DMO）の項目にどのように対応付けるかを定義するプロセスです。データの更新方法の種類ではありません。"
19,Data Cloudでセグメントを作成した後、新しいデータが継続的に取り込まれ、顧客の状況は変化していきます。「過去30日以内にWebサイトを訪問した顧客」という条件でセグメントを作成した場合、このセグメントのメンバーシップを常に最新の状態に保つためには、どのような仕組みが重要になりますか？,データストリームの頻繁な一時停止,アクティベーションターゲットの追加,アイデンティティ解決ルールの削除,セグメントの定期的なリフレッシュ（再評価）,D,"A. データストリームの頻繁な一時停止 - データストリームを停止すると、最新の顧客データがData Cloudに取り込まれなくなるため、セグメントのメンバーシップは古くなってしまいます。これはセグメントを最新に保つ方法ではありません。

B. アクティベーションターゲットの追加 - アクティベーションターゲットを追加することは、セグメントの結果を利用できるシステムを増やすことにはなりますが、セグメントのメンバーシップ自体を最新の状態に更新するプロセスではありません。

C. アイデンティティ解決ルールの削除 - アイデンティティ解決ルールは顧客プロファイルの統合に不可欠であり、これを削除することは通常推奨されません。セグメントのメンバーシップを最新に保つ仕組みとは関係ありません。

D. セグメントの定期的なリフレッシュ（再評価） - 正解です。セグメントの条件は、顧客の行動や属性の変化によって合致する/しなくなる場合があります。そのため、「セグメントの公開スケジュール」を設定するなどして、定義された条件に基づいて定期的にメンバーシップを再評価（リフレッシュ）し、最新の顧客リストを維持することが重要です。"
20,Data Cloudを導入・運用する上で、データの品質、セキュリティ、コンプライアンス、およびライフサイクル全体にわたって、データの適切な管理と利用を保証するための方針、プロセス、および管理体制の確立が重要です。これらのデータ管理に関する包括的な枠組みや活動は、一般的に何と呼ばれますか？,データガバナンス,データアクティベーション,アイデンティティ解決,セグメンテーション,A,"A. データガバナンス - 正解です。データガバナンスは、組織がデータを戦略的な資産として管理・活用するために定める包括的な方針、プロセス、役割、管理体制、およびテクノロジーを指します。データの品質、セキュリティ、プライバシー、コンプライアンス、ライフサイクル管理などが含まれ、Data Cloudの導入・運用においても非常に重要な概念です。

B. データアクティベーション - データアクティベーションは、Data Cloudで準備された顧客セグメントやインサイトを、マーケティングキャンペーンやパーソナライゼーションなどの具体的なアクションのために外部システムへ連携するプロセスを指します。

C. アイデンティティ解決 - アイデンティティ解決は、複数のデータソースに存在する同一の顧客に関するレコードを特定し、統合された顧客プロファイルを作成する技術的なプロセスです。データガバナンスの一部ではありますが、全体を指すものではありません。

D. セグメンテーション - セグメンテーションは、特定の属性や行動に基づいて、ターゲットとなる顧客グループを作成するプロセスです。データガバナンスの枠組みの中で実行される活動の一つですが、枠組みそのものではありません。"
21,顧客がData CloudからAmazon S3クラウドファイルストレージバケットへのデータ有効化を試みています。コンサルタントはData CloudからS3バケットに接続するために、どの認証タイプを推奨すべきでしょうか？,S3プライベートキー証明書を使用する。,S3暗号化されたユーザー名とパスワードを使用する。,S3で生成されたJWTトークンを使用する。,S3アクセスキーとシークレットキーを使用する。,D,"A. S3プライベートキー証明書を使用する - S3プライベートキー証明書は、Amazon S3の認証方法としては一般的ではありません。S3は主にアクセスキーとシークレットキー、またはIAMロールを使用して認証を行います。
B. S3暗号化されたユーザー名とパスワードを使用する - Amazon S3は、ユーザー名とパスワードによる直接的な認証をサポートしていません。S3へのアクセスは、主にアクセスキーとシークレットキー、またはIAMロールに基づいて行われます。
C. S3で生成されたJWTトークンを使用する - JWT（JSON Web Token）は、API認証などで使用されるトークンですが、Amazon S3の直接的な認証方法としては一般的ではありません。S3へのアクセスは、アクセスキーとシークレットキー、またはIAMロールを通じて行われます。
D. S3アクセスキーとシークレットキーを使用する - 正解です。Amazon S3への接続において、アクセスキーとシークレットキーは最も一般的な認証方法の一つです。Data CloudからS3バケットへのデータ有効化を行う際、この認証タイプを使用することで、安全にS3リソースにアクセスできます。"
22,Northern Trail Outfittersは、Data CloudでMarketing Cloudのデータの一部を使用したいと考えています。どのエンゲージメントチャネルデータがカスタム統合を必要としますか？,SMS,メール,CloudPage,モバイルプッシュ,C,"A. SMS - Marketing CloudのSMSデータは、Data Cloudとの統合が比較的容易です。標準的なコネクタやAPIを使用してデータ連携が可能です。
B. メール - Marketing Cloudのメールエンゲージメントデータ（開封、クリックなど）も、Data Cloudとの統合がサポートされています。標準的なコネクタやAPIを利用してデータを連携できます。
C. CloudPage - 正解です。CloudPageは、Marketing CloudでカスタムのWebページを作成するための機能です。CloudPageのデータは、標準的なコネクタやAPIを通じてData Cloudに直接連携することが難しく、カスタム統合が必要となる場合があります。
D. モバイルプッシュ - Marketing Cloudのモバイルプッシュ通知のデータも、Data Cloudとの統合がサポートされています。標準的なコネクタやAPIを使用してデータを連携できます。"
23,"計算インサイトをセグメンテーションキャンバスに表示するために満たす必要のある2つの要件はどれですか？

2つの答えを選択してください。",計算インサイトのメトリクスは数値のみを含む必要があります。,セグメント化されたテーブルの主キーは、計算インサイトのメトリクスである必要があります。,計算インサイトには、個人または統合個人IDを含むディメンションが含まれている必要があります。,セグメント化されたテーブルの主キーは、計算インサイトのディメンションである必要があります。,"C,D","A. 計算インサイトのメトリクスは数値のみを含む必要があります。- 計算インサイトのメトリクスは数値である必要はありません。ディメンションを含むことも可能です。
B. セグメント化されたテーブルの主キーは、計算インサイトのメトリクスである必要があります。- セグメント化されたテーブルの主キーは、計算インサイトのメトリクスである必要はありません。主キーはディメンションである必要があります。
C. 計算インサイトには、個人または統合個人IDを含むディメンションが含まれている必要があります。- 正解です。計算インサイトをセグメンテーションキャンバスで使用するには、個人または統合個人IDを含むディメンションが必要です。これにより、セグメント化の対象となる個人を特定できます。
D. セグメント化されたテーブルの主キーは、計算インサイトのディメンションである必要があります。- 正解です。セグメント化されたテーブルの主キーは、計算インサイトのディメンションである必要があります。これにより、セグメント化の基準となるテーブルのレコードを一意に識別できます。"
24,Data Cloudでアイデンティティ解決のマッチルールを設定する際、複数のルール（例：ルール1「メールアドレス完全一致」、ルール2「氏名ファジー一致＋電話番号完全一致」）を定義することがあります。これらのルールを評価する順序や、どのルールが満たされた場合にレコードを一致とみなすかを制御するためには、どのような設定を利用しますか？,調整ルールの優先順位,データストリームの処理順序,セグメントのフィルタロジック (AND/OR),マッチルールの順序と連結ロジック (Match Rule Order and Logic),D,"A. 調整ルールの優先順位 - 調整ルールは、一致したレコード間で項目値が競合した場合に、どのソースの値を採用するかを決定するルールであり、レコード自体を一致させるためのルール間のロジックを設定するものではありません。

B. データストリームの処理順序 - データストリームの処理順序はデータの取り込みタイミングには影響しますが、アイデンティティ解決において複数のマッチルールがどのように評価され、組み合わされるかを制御するものではありません。

C. セグメントのフィルタロジック (AND/OR) - セグメントのフィルタロジックは、セグメント作成時に複数の条件を組み合わせて対象者を絞り込む際に使用されるものであり、アイデンティティ解決のマッチルールに関する設定ではありません。

D. マッチルールの順序と連結ロジック - 正解です。複数のマッチルールを定義した場合、アイデンティティ解決の設定では、各ルールを評価する順序を指定できます。また、通常はこれらのルールが「OR」条件（定義されたルールのいずれか一つでも満たせば一致とみなす）で評価されるように設定されますが、より高度な連結ロジックを構成することも可能です。これにより、照合プロセスの柔軟性と精度を高めることができます。"
25,"Data Cloudで対応できる2つの一般的なユースケースはどれですか？
2つの答えを選択してください。",より関連性の高い体験を推進するために、顧客データを理解し、行動する。,一元化されたポリシーとプロセスを通じて、エンタープライズデータライフサイクルを管理する。,標準化された拡張可能なデータモデルで、複数のソースからのデータを調和させる。,バックアップおよび災害復旧のための一元化されたシステムとして機能し、重要なビジネスデータを保護する。,"A,C","A. より関連性の高い体験を推進するために、顧客データを理解し、行動する。- 正解です。Data Cloudは、顧客データを統合し、分析することで、よりパーソナライズされた顧客体験を提供するために使用されます。
B. 一元化されたポリシーとプロセスを通じて、エンタープライズデータライフサイクルを管理する。- Data Cloudは、データライフサイクル管理の一部をサポートしますが、エンタープライズ全体のデータライフサイクル管理を主な目的としていません。
C. 標準化された拡張可能なデータモデルで、複数のソースからのデータを調和させる。- 正解です。Data Cloudは、異なるソースからのデータを統合し、標準化されたデータモデルに変換することで、データの整合性を高めます。
D. バックアップおよび災害復旧のための一元化されたシステムとして機能し、重要なビジネスデータを保護する。- Data Cloudは、バックアップや災害復旧の主要なシステムとして設計されていません。主に顧客データの統合と活用に焦点を当てています。"
26,Data Cloudでデータモデルオブジェクト（DMO）を設計する際、項目をその性質に応じて「ディメンション」または「メジャー」として分類することが推奨されます。顧客の氏名、メールアドレス、居住地などの記述的な属性情報は、通常どちらのカテゴリに分類されますか？,メジャー (Measure),ディメンション (Dimension),カテゴリ (Category),リレーションシップ (Relationship),B,"A. メジャー (Measure) - メジャーは、売上金額、数量、Webサイト滞在時間など、定量的な測定値や計算に使用される数値を表す項目です。顧客の氏名やメールアドレスのような記述的な属性情報はメジャーには分類されません。

B. ディメンション (Dimension) - 正解です。ディメンションは、データを分析する際の切り口や分類軸となる記述的な属性を表す項目です。顧客の氏名、メールアドレス、居住地の都道府県、性別、製品カテゴリなどがディメンションに該当します。これらの属性を使って、メジャー（測定値）をグループ化したりフィルタリングしたりします。

C. カテゴリ (Category) - データモデルオブジェクト（DMO）自体が、プロファイル、エンゲージメント、その他のカテゴリに分類されますが、DMO内の個々の項目を分類する用語として「カテゴリ」は一般的ではありません。

D. リレーションシップ (Relationship) - リレーションシップは、異なるデータモデルオブジェクト（DMO）間の関連付け（例：「個人」DMOと「購入履歴」DMOの関連）を定義するものであり、個々の項目の性質（属性か測定値か）を示す分類ではありません。"
27,Data Cloudでセグメントを作成し、アクティベーションを設定してMarketing Cloud Engagementに連携する場合、Data Cloudは連携対象となる顧客プロファイルの情報を保持します。この、特定のアクティベーションに含まれる（＝送信される）個々の顧客プロファイルと、それに関連付けられた属性情報のセットは、Data Cloud内で何と呼ばれますか？,データソースオブジェクト (DSO),セグメント定義 (Segment Definition),アクティベーションメンバーシップ (Activation Membership),統合プロファイル (Unified Profile),C,"A. データソースオブジェクト (DSO) - DSOはデータソースから取り込んだデータを保持するオブジェクトであり、アクティベーションによってターゲットシステムに送信される、選択された顧客プロファイルとその属性情報のセットではありません。

B. セグメント定義 (Segment Definition) - セグメント定義は、どのような条件で顧客プロファイルをグループ化するかというルール自体を指します。アクティベーションで実際に送信されるメンバーのリストや属性情報ではありません。

C. アクティベーションメンバーシップ (Activation Membership) - 正解です。アクティベーションメンバーシップは、特定のアクティベーション設定を実行した結果として、ターゲットシステムに送信される対象となった統合プロファイルの集合と、その際に含めるように指定された属性（例：連絡先情報、計算済みインサイトなど）のデータを指します。

D. 統合プロファイル (Unified Profile) - 統合プロファイルは、アイデンティティ解決によって作成された個々の顧客の包括的なレコードです。アクティベーションメンバーシップは、これらの統合プロファイルの中から、セグメント条件に合致し、かつアクティベーションの対象となったもののリストと選択された属性情報の組み合わせです。"
28,Northern Trail Outfitters（NTO）は、あいまいな名前と正規化されたメールに基づくID解決ルールセットを設定しています。NTOは、最適なメールアドレスが有効化されるようにするために何をすべきでしょうか？,取引先責任者連絡先メールオブジェクトの有効項目を一致ルールとして含めます。,有効化でソース優先順位を使用して、目的のソースからの連絡先が有効化ターゲットに配信されるようにします。,Marketing Cloudがソース優先順位調整ルールで最初のデータソースとして優先されるようにします。,デフォルトの調整ルールを最終更新に設定します。,B,"A. 取引先責任者連絡先メールオブジェクトの有効項目を一致ルールとして含めます。- 有効項目を一致ルールに含めることは、メールアドレスの有効性を確認するのに役立ちますが、最適なメールアドレスの選択には直接影響しません。
B. 有効化でソース優先順位を使用して、目的のソースからの連絡先が有効化ターゲットに配信されるようにします。- 正解です。ソース優先順位を使用することで、信頼性の高いソースからのメールアドレスを優先的に選択できます。これにより、最適なメールアドレスが有効化ターゲットに配信されることを保証できます。
C. Marketing Cloudがソース優先順位調整ルールで最初のデータソースとして優先されるようにします。- Marketing Cloudを優先することは、特定のシナリオでは有効ですが、常に最適なメールアドレスを選択できるとは限りません。ソースの信頼性に基づいて優先順位を設定する必要があります。
D. デフォルトの調整ルールを最終更新に設定します。- 最終更新を調整ルールに設定することは、最新のデータを選択するのに役立ちますが、最適なメールアドレスの選択には直接影響しません。"
29,コンサルタントは、顧客注文からの住所詳細が統合プロファイルに保存するために最適に選択されるようにしたいと考えています。コンサルタントはこれを達成するために何をすべきでしょうか？,連絡先住所の詳細を選択します。特定の住所属性の調整ルールをソース優先順位に変更し、個人DMOを一番下に移動します。,連絡先住所のデフォルトの調整ルールを使用します。,連絡先住所の詳細を選択します。特定の住所属性の調整ルールをソース優先順位に変更し、注文DMOを一番上に移動します。,個人のデフォルトの調整ルールをソース優先順位に変更します。,C,"A. 連絡先住所の詳細を選択します。特定の住所属性の調整ルールをソース優先順位に変更し、個人DMOを一番下に移動します。- 個人DMOを一番下に移動すると、注文データよりも個人データが優先されなくなるため、顧客注文からの住所詳細を最適に選択できません。
B. 連絡先住所のデフォルトの調整ルールを使用します。- デフォルトの調整ルールでは、必ずしも最適な住所詳細が選択されるとは限りません。ソース優先順位を使用して、注文データを優先する必要があります。
C. 連絡先住所の詳細を選択します。特定の住所属性の調整ルールをソース優先順位に変更し、注文DMOを一番上に移動します。- 正解です。注文DMOを一番上に移動し、ソース優先順位を使用することで、顧客注文からの住所詳細を優先的に選択できます。これにより、最も正確で最新の住所情報が統合プロファイルに保存されます。
D. 個人のデフォルトの調整ルールをソース優先順位に変更します。- 個人のデフォルトの調整ルールを変更しても、注文データが優先されるわけではありません。注文DMOを優先的に設定する必要があります。"
30,コンサルタントは、以前に黒いパンツを購入した顧客向けに新製品の発売を発表するセグメントを作成しています。この基準を満たすために、コンサルタントは注文製品オブジェクトから製品の色と製品タイプの属性をどのように配置すべきですか？,製品色の属性を1つのコンテナに、製品タイプの属性を別のコンテナに配置します。,動的に適用される「黒」計算インサイトの属性を配置します。,製品と製品タイプの属性を直接属性として配置します。,製品色と製品タイプの属性を単一のコンテナに配置します。,D,"A. 製品色の属性を1つのコンテナに、製品タイプの属性を別のコンテナに配置します。- 別のコンテナに配置すると、「黒いパンツ」という特定の組み合わせを正確に表現できません。両方の条件を同時に満たす必要があるため、単一のコンテナに配置する必要があります。
B. 動的に適用される「黒」計算インサイトの属性を配置します。- 「黒」計算インサイトを使用することも可能ですが、直接属性を使用する方がシンプルで効率的です。
C. 製品と製品タイプの属性を直接属性として配置します。- 直接属性として配置すると、両方の属性を組み合わせることができません。特定の条件を満たすためには、コンテナを使用する必要があります。
D. 製品色と製品タイプの属性を単一のコンテナに配置します。- 正解です。単一のコンテナに両方の属性を配置することで、「黒いパンツ」という特定の組み合わせを正確に表現できます。これにより、セグメントは必要な顧客を正確にターゲットにできます。"
31,顧客にとってのData Cloudの主な価値は何ですか？,すべての匿名データの単一の信頼できる情報源を作成すること。,顧客の行動を聴き、理解し、行動することで、パーソナライズされたキャンペーンを作成すること。,すべてのシステムをゴールデンレコードで接続すること。,顧客とその関連データの統合ビューを提供すること。,D,"A. すべての匿名データの単一の信頼できる情報源を作成すること。- Data Cloudは匿名データだけでなく、個人識別情報（PII）を含む顧客データを統合します。
B. 顧客の行動を聴き、理解し、行動することで、パーソナライズされたキャンペーンを作成すること。- これはData Cloudの重要な機能の一つですが、主な価値ではありません。主な価値は、顧客データの統合と統一ビューの提供です。
C. すべてのシステムをゴールデンレコードで接続すること。- ゴールデンレコードはData Cloudの重要な概念ですが、主な価値はシステム接続ではなく、顧客データの統合です。
D. 顧客とその関連データの統合ビューを提供すること。- 正解です。Data Cloudの主な価値は、複数のソースからの顧客データを統合し、顧客とその関連データの統一されたビューを提供することです。これにより、企業は顧客をより深く理解し、より効果的な顧客体験を提供できます。"
32,コンサルタントがセグメントエラーのトラブルシューティングを行っています。ネストされたセグメントの代わりに計算インサイトを使用することで解決されるエラーメッセージはどれですか？,セグメントが複雑すぎます。,複数の人口カウントが進行中です。,セグメントの人口カウントに失敗しました。,セグメントを公開できません。,A,"A. セグメントが複雑すぎます。- 正解です。ネストされたセグメントは、特に複雑な条件や複数のレベルにわたる条件を扱う場合に、セグメントの複雑さを増大させ、エラーを引き起こす可能性があります。計算インサイトを使用することで、複雑な条件を事前に計算し、セグメントの複雑さを軽減できます。
B. 複数の人口カウントが進行中です。- このエラーは、セグメントの人口カウントが同時に複数実行されている場合に発生し、計算インサイトの使用とは直接関係ありません。
C. セグメントの人口カウントに失敗しました。- このエラーは、セグメントの人口カウント処理中に予期しない問題が発生した場合に発生し、計算インサイトの使用とは直接関係ありません。
D. セグメントを公開できません。- このエラーは、セグメントの公開に必要な条件が満たされていない場合に発生し、計算インサイトの使用とは直接関係ありません。"
33,組織が在庫管理システムからData Cloudに在庫レベルを高速かつスケーラブルなほぼリアルタイムの方法でストリーミングするために使用すべきものは何ですか？,クラウドストレージコネクタ,Commerce Cloudコネクタ,取り込みAPI,Marketing Cloudパーソナライズコネクタ,C,"A. クラウドストレージコネクタ - クラウドストレージコネクタは、クラウドストレージサービス（Amazon S3、Google Cloud Storageなど）からのバッチデータ取り込みに使用されます。リアルタイムのデータストリーミングには適していません。
B. Commerce Cloudコネクタ - Commerce Cloudコネクタは、Salesforce Commerce CloudからのデータをData Cloudに取り込むために使用されます。在庫管理システムからのリアルタイムデータストリーミングには適していません。
C. 取り込みAPI - 正解です。取り込みAPIは、リアルタイムまたはほぼリアルタイムのデータストリーミングに最適です。高速でスケーラブルなデータ取り込みをサポートし、在庫レベルなどの動的なデータをData Cloudにストリーミングするのに適しています。
D. Marketing Cloudパーソナライズコネクタ - Marketing Cloudパーソナライズコネクタは、Marketing Cloud PersonalizationからのデータをData Cloudに取り込むために使用されます。在庫管理システムからのリアルタイムデータストリーミングには適していません。"
34,カスタムSalesforce CRMオブジェクトが新規データストリーム構成で使用できない場合、コンサルタントはどの権限設定を確認する必要がありますか？,Data Cloud組織でオブジェクト作成権限が有効になっていることを確認します。,ソースSalesforce CRM組織でオブジェクトのすべての表示権限が有効になっていることを確認します。,Salesforce CRM組織でオブジェクト取り込み権限が有効になっていることを確認します。,Data Cloud組織でオブジェクト変更権限が有効になっていることを確認します。,B,"A. Data Cloud組織でオブジェクト作成権限が有効になっていることを確認します。- Data Cloud組織でのオブジェクト作成権限は、新しいオブジェクトを作成する権限であり、既存のCRMオブジェクトの表示には影響しません。
B. ソースSalesforce CRM組織でオブジェクトのすべての表示権限が有効になっていることを確認します。- 正解です。Data CloudがソースSalesforce CRM組織からオブジェクトを読み取るためには、ソース組織で「すべての表示」権限が必要です。この権限がない場合、オブジェクトはデータストリーム構成で使用できません。
C. Salesforce CRM組織でオブジェクト取り込み権限が有効になっていることを確認します。- オブジェクト取り込み権限は、特定のオブジェクトのデータを取り込むための権限ですが、オブジェクトの表示には直接影響しません。
D. Data Cloud組織でオブジェクト変更権限が有効になっていることを確認します。- Data Cloud組織でのオブジェクト変更権限は、Data Cloud内のオブジェクトを変更する権限であり、ソースCRMオブジェクトの表示には影響しません。"
35,Data Cloudは、Salesforce CRMやクラウドストレージなど、標準で多くのデータソースへの接続機能を提供しています。しかし、標準コネクタが提供されていない特定の外部システム（例：業界特化型アプリケーション、オンプレミスデータベース）からデータを取り込みたい場合、コンサルタントはどのような解決策を検討すべきでしょうか？,AppExchangeで提供されているサードパーティ製のData Cloudコネクタを探す。,データストリームタイプとして「Salesforce CRM」を選択し、手動で項目をマッピングする。,計算済みインサイトを使用して外部システムからデータを取得する。,アクティベーションターゲットとして外部システムを設定する。,A,"A. AppExchangeで提供されているサードパーティ製のData Cloudコネクタを探す。 - 正解です。Data Cloudが標準で提供するコネクタで対応できないデータソースの場合、Salesforce AppExchangeでパートナー企業が開発・提供している専用のコネクタが存在する可能性があります。これらを利用することで、コーディングなしに特定の外部システムからData Cloudへデータを連携できる場合があります。また、MuleSoft Anypoint PlatformやIngestion APIを利用したカスタム連携も選択肢となります。

B. データストリームタイプとして「Salesforce CRM」を選択し、手動で項目をマッピングする。 - Salesforce CRMコネクタは、SalesforceのCRM組織（Sales Cloud、Service Cloudなど）からデータを取り込むためのものであり、一般的な外部システムやオンプレミスデータベースへの接続には使用できません。

C. 計算済みインサイトを使用して外部システムからデータを取得する。 - 計算済みインサイトは、既にData Cloud内に存在するデータに基づいて新たな指標や属性を計算するための機能であり、外部システムからデータを取り込むためのコネクタ機能ではありません。

D. アクティベーションターゲットとして外部システムを設定する。 - アクティベーションターゲットは、Data Cloudで処理された結果（セグメントメンバーなど）を外部システムに送信するための設定です。外部システムからデータを取り込むためのものではありません。"
36,ユーザーはData Cloudでセグメントを作成し、有効化の作成プロセス中です。関連属性を選択する際に、個人に関連付けられていることがわかっている特定の属性セットを見つけることができません。これらの属性が利用できない理由を説明する記述はどれですか？,セグメントがプロファイルデータをセグメント化していません。,属性が別の有効化で使用されています。,目的の属性が異なる関連パスに存在します。,有効化には1対1の属性のみを含めることができます。,C,"A. セグメントがプロファイルデータをセグメント化していません。- セグメントがプロファイルデータをセグメント化していない場合、属性が利用できない可能性がありますが、特定の属性セットが見つからない理由としては不十分です。
B. 属性が別の有効化で使用されています。- 属性が別の有効化で使用されている場合でも、通常は利用可能です。有効化は属性の可用性を制限しません。
C. 目的の属性が異なる関連パスに存在します。- 正解です。Data Cloudのデータモデルでは、属性は異なる関連パスに存在することがあります。有効化で属性を利用するには、セグメントと属性が同じ関連パスを共有している必要があります。異なる関連パスにある属性は利用できません。
D. 有効化には1対1の属性のみを含めることができます。- 有効化には1対多の属性も含めることができます。1対1の属性のみという制限はありません。"
37,Data Cloudでは、異なるソースからのデータ構造を標準化し、相互運用性を高めるために共通のデータモデルが利用されます。Salesforceが提供し、Data Cloudの多くの標準機能（データマッピング、セグメンテーション、インサイトなど）の基盤となっているこのオープンソースのデータモデルは何と呼ばれますか？,CIM（Cloud Information Model）,DSO（Data Source Object）,DMO（Data Model Object）,SOQL（Salesforce Object Query Language）,A,"A. CIM（Cloud Information Model） - 正解です。CIMは、Salesforceが中心となって開発を進めているオープンソースの標準データモデルであり、様々なクラウドアプリケーションやデータソース間でのデータの一貫性と相互運用性を促進することを目的としています。Data Cloudのデータモデリングは、このCIMの概念に基づいて構築されており、多くの標準DMOがCIMに準拠しています。
B. DSO（Data Source Object） - DSOは、データストリームを通じて外部ソースから取り込まれたデータを、元のスキーマに近い形で一時的に格納するData Cloud内のオブジェクトです。標準データモデルそのものではありません。
C. DMO（Data Model Object） - DMOは、Data Cloud内で正規化され、分析やセグメンテーションなどに利用されるデータを格納するオブジェクトです。DMOはCIMに基づいて作成されることが推奨されますが、DMOという用語自体が標準データモデルの名前ではありません。
D. SOQL（Salesforce Object Query Language） - SOQLは、Salesforceプラットフォーム上のオブジェクトからデータを取得するためのクエリ言語です。データ構造を定義するデータモデルではありません。"
38,顧客は、特定のセグメントの有効化が失敗するたびに通知を受け取る必要があるという要件を持っています。コンサルタントはこのユースケースを解決するためにどの機能を使用すべきですか？,フロー,レポート,有効化アラート,ダッシュボード,C,"A. フロー - フローは、自動化されたビジネスプロセスを作成するために使用されますが、有効化の失敗に関する通知機能は直接提供しません。
B. レポート - レポートは、データの集計と表示に使用されますが、有効化の失敗に関するリアルタイム通知機能は提供しません。
C. 有効化アラート - 正解です。有効化アラートは、特定のセグメントの有効化が失敗した場合に通知を送信する機能です。この機能を使用することで、顧客は有効化の失敗をリアルタイムで把握し、迅速に対応できます。
D. ダッシュボード - ダッシュボードは、データの視覚的な概要を提供しますが、有効化の失敗に関するリアルタイム通知機能は提供しません。"
39,Northern Trail Outfittersは、Track My Runモバイルアプリからランナープロファイルとアクティビティログを抽出し、Data Cloudにロードするようにコンサルタントに依頼します。マーケティング部門は、過去90日間の履歴データが必要であり、今後利用可能になるすべての新規および更新データを必要としていることも示しています。ベストプラクティスとして、コンサルタントはこのリクエストを実装するためにどのようなアクションシーケンスを使用すべきですか？,過去90日間のデータを最初にロードするために一括取り込みを使用し、今後利用可能になる将来のデータを同期するために一括取り込みを継続的に使用します。,過去90日間のデータを最初にロードするためにストリーミング取り込みを使用し、今後利用可能になる将来のデータを同期するためにストリーミング取り込みを継続的に使用します。,過去90日間のデータを最初にロードするためにストリーミング取り込みを使用し、今後利用可能になる将来のデータを同期するために一括取り込みを使用します。,過去90日間のデータを最初にロードするために一括取り込みを使用し、今後利用可能になる将来のデータを同期するためにストリーミング取り込みを使用します。,D,"A. 過去90日間のデータを最初にロードするために一括取り込みを使用し、今後利用可能になる将来のデータを同期するために一括取り込みを継続的に使用します。- 一括取り込みは、大量の履歴データを効率的にロードするのに適していますが、リアルタイムのデータ更新には適していません。
B. 過去90日間のデータを最初にロードするためにストリーミング取り込みを使用し、今後利用可能になる将来のデータを同期するためにストリーミング取り込みを継続的に使用します。- ストリーミング取り込みは、リアルタイムのデータ更新には適していますが、大量の履歴データを最初にロードするには効率が悪い場合があります。
C. 過去90日間のデータを最初にロードするためにストリーミング取り込みを使用し、今後利用可能になる将来のデータを同期するために一括取り込みを使用します。- 履歴データをストリーミングでロードするのは効率が悪く、将来のデータを一括で同期するのはリアルタイム性に欠けます。
D. 過去90日間のデータを最初にロードするために一括取り込みを使用し、今後利用可能になる将来のデータを同期するためにストリーミング取り込みを使用します。- 正解です。過去90日間の大量の履歴データを最初にロードするには、一括取り込みが効率的です。その後、リアルタイムのデータ更新を同期するために、ストリーミング取り込みを使用するのがベストプラクティスです。"
40,Marketing Cloudの購読者プロファイル属性をData Cloudに毎日取り込む簡単な方法を提供するソリューションはどれですか？,Automation StudioとプロファイルファイルAPI,Marketing Cloud Connect API,Marketing Cloudデータ拡張データストリーム,Email Studioスターターデータバンドル,C,"A. Automation StudioとプロファイルファイルAPI - Automation StudioとプロファイルファイルAPIは、Marketing Cloudからデータをエクスポートし、Data Cloudに取り込むために使用できますが、毎日の自動取り込みを簡単に行う方法ではありません。
B. Marketing Cloud Connect API - Marketing Cloud Connect APIは、Marketing CloudとSalesforce CRM間のデータ統合に使用されます。Data Cloudへの直接的なデータ取り込みには適していません。
C. Marketing Cloudデータ拡張データストリーム - 正解です。Marketing Cloudデータ拡張データストリームは、Marketing Cloudの購読者プロファイル属性をData Cloudに毎日自動的に取り込む簡単な方法を提供します。データストリームを設定することで、毎日のデータ取り込みを自動化できます。
D. Email Studioスターターデータバンドル - Email Studioスターターデータバンドルは、Email Studioの基本的なデータ連携を提供しますが、購読者プロファイル属性の毎日の取り込みには適していません。"
41,Cumulus Financialは、各顧客の毎日の取引量をリアルタイムで追跡し、顧客の通常範囲外の量を検出するとすぐに通知を送信したいと考えています。コンサルタントはこのリクエストに対応するために何をすべきでしょうか？,計算インサイトとフローを組み合わせる。,ストリーミングデータ変換とフローを組み合わせる。,ストリーミングインサイトとデータアクションを組み合わせる。,ストリーミングデータ変換とデータアクションを組み合わせる。,C,"A. 計算インサイトとフローを組み合わせる。- 計算インサイトは、バッチデータに基づいて計算を行うため、リアルタイムの取引量追跡には適していません。フローは、自動化されたビジネスプロセスを実行しますが、リアルタイムのデータ監視と通知には直接対応していません。
B. ストリーミングデータ変換とフローを組み合わせる。- ストリーミングデータ変換は、リアルタイムのデータ処理に適していますが、直接的な通知機能は提供しません。フローは、通知機能を実行できますが、リアルタイムのデータ監視にはストリーミングインサイトが必要です。
C. ストリーミングインサイトとデータアクションを組み合わせる。- 正解です。ストリーミングインサイトは、リアルタイムのデータストリームを監視し、特定の条件が満たされた場合にアラートを生成します。データアクションは、アラートに基づいて通知を送信するなどのアクションを実行できます。これにより、顧客の取引量が通常範囲外になった場合にリアルタイムで通知を送信できます。
D. ストリーミングデータ変換とデータアクションを組み合わせる。- ストリーミングデータ変換は、リアルタイムのデータ処理に適していますが、直接的な監視と通知機能は提供しません。データアクションは、アクションを実行できますが、リアルタイムのデータ監視にはストリーミングインサイトが必要です。"
42,顧客は、取引先統合全体の統合率が低いことに気付きました。取引先を個人および取引先責任者電話メールDMOにマッピングしました。統合率を向上させるために何をすべきでしょうか？,調整ルールを最頻値に変更します。,個人IDルールセットを無効にします。,一致ルールの数を増やします。,データソースで取引先住所の詳細を更新します。,C,"A. 調整ルールを最頻値に変更します。- 調整ルールを最頻値に変更することは、統合率に影響を与える可能性がありますが、アカウント統合の主な問題解決策ではありません。
B. 個人IDルールセットを無効にします。- 個人IDルールセットを無効にすると、個人レベルでの統合が停止し、アカウント統合には影響を与えません。
C. 一致ルールの数を増やします。- 正解です。一致ルールの数を増やすことで、より多くの取引先を統合できる可能性が高まります。特に、アカウント統合において、より多くの一致条件を設定することは統合率を向上させる効果的な方法です。
D. データソースで取引先住所の詳細を更新します。- 取引先住所の詳細を更新することは、データ品質を向上させる上で重要ですが、アカウント統合の主な問題解決策ではありません。"
43,Universal Containersは、現在利用しているSalesforce Sales Cloudの取引先、取引先責任者、商談データをData Cloudに取り込み、他のデータソースと統合して顧客の全体像を把握したいと考えています。Sales CloudのデータをData Cloudに連携させるために、最も一般的に使用される標準的な接続方法はどれでしょうか？,Marketing Cloudコネクタ,Salesforce CRMコネクタ,MuleSoft Anypoint Platform,Interaction Studioコネクタ,B,"A. Marketing Cloudコネクタ - Marketing Cloudコネクタは、Marketing Cloud EngagementやMarketing Cloud Account Engagement（旧Pardot）などのマーケティング関連のデータをData Cloudに取り込むために使用されます。Sales CloudのCRMデータを直接取り込むための主要なコネクタではありません。
B. Salesforce CRMコネクタ - 正解です。Salesforce CRMコネクタは、Data Cloudが標準で提供するコネクタであり、Sales CloudやService Cloudが稼働しているSalesforce組織から標準オブジェクト（取引先、取引先責任者、商談、ケースなど）やカスタムオブジェクトのデータを簡単にData Cloudへ連携させるために最も一般的に利用されます。
C. MuleSoft Anypoint Platform - MuleSoftは強力なシステム連携プラットフォームであり、Data Cloudへのデータ連携にも利用できますが、Salesforce CRM内のデータを取り込むだけであれば、通常は標準のSalesforce CRMコネクタの方がより簡単で直接的な方法です。MuleSoftはより複雑な変換やオーケストレーションが必要な場合に適しています。
D. Interaction Studioコネクタ - Interaction Studio（現Marketing Cloud Personalization）コネクタは、Marketing Cloud PersonalizationからリアルタイムのWeb行動データなどをData Cloudに取り込むために使用されます。Sales CloudのCRMデータを取り込むためのものではありません。"
44,顧客が個人データの削除を要求しています。コンサルタントはData Cloudでこの要求に対応するためにどのようなアクションを取るべきですか？,ストリーミングAPI呼び出しを使用して顧客の情報を削除します。,プロファイルエクスプローラーを使用してData Cloudから顧客データを削除します。,同意APIを使用して顧客情報の削除を要求します。,データ権利主体要求ツールを使用して顧客情報の削除を要求します。,C,"A. ストリーミングAPI呼び出しを使用して顧客の情報を削除します。- ストリーミングAPIは、リアルタイムのデータ処理に使用されますが、個人データの削除要求を処理するための適切なツールではありません。
B. プロファイルエクスプローラーを使用してData Cloudから顧客データを削除します。- プロファイルエクスプローラーは、プロファイルデータを表示および分析するためのツールであり、個人データの削除要求を処理するためのものではありません。
C. 同意APIを使用して顧客情報の削除を要求します。- 正解です。同意APIは、顧客の同意およびデータ権利要求を管理するために使用されます。個人データの削除要求を処理するために、同意APIを使用する必要があります。
D. データ権利主体要求ツールを使用して顧客情報の削除を要求します。- データ権利主体要求ツールは、顧客がデータ権利要求を送信するためのツールですが、Data Cloud内で直接削除要求を処理するものではありません。削除要求の処理には、同意APIを使用する必要があります。"
45,Data CloudのWebおよびモバイルアプリケーションコネクタに関する記述のうち、正しいものはどれですか？,コネクタの設定時に、イベント、プロファイル、トランザクションデータを含む標準スキーマが作成されます。,テナント固有のエンドポイントは、コネクタの設定時にData Cloudで自動生成されます。,コネクタに関連付けられたデータストリームは、Data Cloud設定からアプリを削除すると自動的に削除されます。,コネクタスキーマは、既存のフィールドを削除するように更新できます。,B,"A. コネクタの設定時に、イベント、プロファイル、トランザクションデータを含む標準スキーマが作成されます。- コネクタの設定時に標準スキーマが自動的に作成されるわけではありません。スキーマは、取り込むデータに基づいてユーザーが定義する必要があります。
B. テナント固有のエンドポイントは、コネクタの設定時にData Cloudで自動生成されます。- 正解です。Webおよびモバイルアプリケーションコネクタを設定する際、Data Cloudはテナント固有のエンドポイントを自動的に生成します。このエンドポイントを使用して、アプリケーションからData Cloudにデータを送信します。
C. コネクタに関連付けられたデータストリームは、Data Cloud設定からアプリを削除すると自動的に削除されます。- アプリを削除しても、関連するデータストリームは自動的に削除されません。データストリームは手動で削除する必要があります。
D. コネクタスキーマは、既存のフィールドを削除するように更新できます。- コネクタスキーマは、フィールドの追加や変更は可能ですが、既存のフィールドを削除することはできません。"
46,Data Cloudで「高エンゲージメント顧客」セグメントを作成し、Marketing Cloud Engagementをアクティベーションターゲットとして設定しました。セグメントの公開スケジュールが「毎日」に設定されている場合、アクティベーションターゲットであるMarketing Cloud Engagementのデータエクステンション（または他のリスト）のメンバーは、通常どのように更新されますか？,セグメントのメンバーが変更されるたびにリアルタイムで更新される。,セグメントの公開スケジュール（この場合は毎日）に従って、その時点での最新メンバーリストに更新される。,Data Cloudコンサルタントが手動で更新操作を行った場合にのみ更新される。,アクティベーションターゲットの設定時に一度だけ同期され、その後は更新されない。,B,"A. セグメントのメンバーが変更されるたびにリアルタイムで更新される。 - Data Cloudのセグメント評価とアクティベーションプロセスは、通常、設定されたスケジュールに基づいて実行されるバッチ処理です。メンバーシップの変更が即座にリアルタイムでアクティベーションターゲットに反映されるわけではありません。

B. セグメントの公開スケジュール（この場合は毎日）に従って、その時点での最新メンバーリストに更新される。 - 正解です。セグメントに公開スケジュール（例：毎日、毎週）を設定すると、そのスケジュールに従ってData Cloudはセグメントのメンバーシップを再評価します。その後、アクティベーションが実行されると、アクティベーションターゲット（例：Marketing Cloudのデータエクステンション）の内容が、その時点での最新のセグメントメンバーリストで更新（上書きまたは差分更新）されます。

C. Data Cloudコンサルタントが手動で更新操作を行った場合にのみ更新される。 - セグメントの公開やアクティベーションはスケジュールに基づいて自動実行できるため、毎回手動で操作する必要はありません。手動での実行も可能ですが、それが唯一の方法ではありません。

D. アクティベーションターゲットの設定時に一度だけ同期され、その後は更新されない。 - アクティベーションは通常、継続的な連携を目的としており、設定されたスケジュールに従って定期的にターゲットシステムを更新します。一度だけの同期ではありません。"
47,Data Cloudのアイデンティティ解決プロセスにおいて、一度作成された統合プロファイルが、後から連携されたより信頼性の高いデータや、顧客からの情報の訂正・削除依頼などによって、分割されたり、他のプロファイルと再結合されたりする必要が出てくる場合があります。このような状況に対応し、統合プロファイルの構成を動的に調整するために使用されるルールは何でしょうか？,マッチルール (Match Rule),正規化ルール (Normalization Rule),セグメントルール (Segmentation Rule),再調整ルール (Reconciliation Rule),D,"A. マッチルール (Match Rule) - マッチルールは、どのソースレコードが同じ個人に属するかを最初に特定するためのルールです。既に作成された統合プロファイルを後から調整するルールではありません。

B. 正規化ルール (Normalization Rule) - 正規化ルールは、データを取り込む際や照合する前に、データ形式を統一するためのルール（例：電話番号のフォーマット統一）であり、プロファイルの構成を調整するものではありません。

C. セグメントルール (Segmentation Rule) - セグメントルールは、特定の条件に基づいて統合プロファイルをグループ化するためのルールであり、プロファイル自体の統合や分割を制御するものではありません。

D. 再調整ルール (Reconciliation Rule) - 正解です。再調整ルールは、アイデンティティ解決プロセスにおいて、初期の統合後に状況が変化した場合（例：より信頼性の高い識別子を持つデータが後から連携された、顧客からデータの訂正・削除要求があったなど）に、統合プロファイルの構成を見直し、必要に応じてプロファイルを分割したり、これまで別々だったプロファイルを新たに結合したりするためのロジックを定義します。"
48,Northern Trail Outfittersは、Data Cloudに取り込むために、毎日Amazon S3バケットに新しい顧客データをアップロードします。新しくインポートされたデータがすべてのセグメントで使用できるように準備完了となるように、各プロセスをどのような順序で実行する必要がありますか？,計算インサイト > データストリームの更新 > ID解決,データストリームの更新 > 計算インサイト > ID解決,ID解決 > データストリームの更新 > 計算インサイト,データストリームの更新 > ID解決 > 計算インサイト,D,"A. 計算インサイト > データストリームの更新 > ID解決 - データストリームの更新前に計算インサイトを実行すると、古いデータに基づいて計算が行われるため、最新のデータを使用できません。
B. データストリームの更新 > 計算インサイト > ID解決 - ID解決前に計算インサイトを実行すると、統合されていないデータに基づいて計算が行われるため、正確な結果が得られない可能性があります。
C. ID解決 > データストリームの更新 > 計算インサイト - データストリームを更新する前にID解決を実行すると、古いデータに基づいて統合が行われるため、最新のデータを使用できません。
D. データストリームの更新 > ID解決 > 計算インサイト - 正解です。まずデータストリームを更新して最新のデータを取り込み、次にID解決を実行してデータを統合し、最後に計算インサイトを実行して統合されたデータに基づいて計算を行う必要があります。この順序により、最新の統合されたデータに基づいてセグメントが使用できるようになります。"
49,Universal Containersは、Data Cloudに蓄積された顧客の購買履歴データとWebサイト行動データを利用して、各顧客の「生涯価値（LTV - Lifetime Value）」や「エンゲージメントスコア」といった指標を計算し、セグメンテーションやパーソナライゼーションに活用したいと考えています。Data Cloud内で、定義に基づいて集計や計算を行い、これらの指標を作成する機能は何でしょうか？,データストリーム,アクティベーション,計算済みインサイト,アイデンティティ解決,C,"A. データストリーム - データストリームは、様々なデータソースからData Cloudへデータを継続的に取り込むための接続設定です。指標の計算を行う機能ではありません。
B. アクティベーション - アクティベーションは、Data Cloudで作成されたセグメントやインサイトの結果を、外部のマーケティングツールやSalesforceアプリケーションに送信するためのプロセスです。指標の計算自体を行うものではありません。
C. 計算済みインサイト - 正解です。計算済みインサイトは、Data Cloud内のデータモデルオブジェクト（DMO）に格納されたデータを使用して、SQLに似た関数や演算子を用いて複雑な集計や計算（例：合計、平均、ウィンドウ関数など）を行い、顧客の生涯価値（LTV）やエンゲージメントスコアといった新しいインサイト（指標や属性）を生成する機能です。
D. アイデンティティ解決 - アイデンティティ解決は、異なるデータソースからの顧客レコードを照合し、単一の統合プロファイルを作成するプロセスです。指標の計算を行う機能ではありません。"
50,顧客はSalesforce CRMとリアルタイムで統合する必要があります。この要件を達成する機能はどれですか？,ストリーミング変換,データモデルトリガー,Sales and Serviceバンドル,データアクションとLightning Webコンポーネント,A,"A. ストリーミング変換 - 正解です。ストリーミング変換は、リアルタイムでデータを処理し、Salesforce CRMとの統合に必要なデータ変換を即座に行うことができます。
B. データモデルトリガー - データモデルトリガーは、データモデル内の変更に基づいてアクションを実行しますが、リアルタイムのデータ統合には適していません。トリガーは通常、非同期的に実行されます。
C. Sales and Serviceバンドル - Sales and Serviceバンドルは、Salesforceのセールスおよびサービス機能をData Cloudと統合するためのプリパッケージされたデータセットと設定ですが、リアルタイム統合を直接提供するものではありません。
D. データアクションとLightning Webコンポーネント - データアクションとLightning Webコンポーネントは、Data CloudからSalesforce CRMへのアクションをトリガーするために使用できますが、リアルタイムのデータ統合を直接提供するものではありません。ストリーミング変換は、リアルタイムのデータ処理と統合に特化しています。"
51,Data Cloudは、顧客データの高可用性と耐障害性をどのように保証しますか？,複数のリージョンとデータセンターにデータを分散させることによって。,強力なバックアップを備えたデータセンターを使用することによって。,自動データ復旧手順を実装することによって。,必須要員へのデータアクセスを制限することによって。,A,"A. 複数のリージョンとデータセンターにデータを分散させることによって。- 正解です。Data Cloudは、データを複数のリージョンとデータセンターに分散させることで、高可用性と耐障害性を確保します。これにより、1つのデータセンターで障害が発生した場合でも、他のデータセンターからデータにアクセスできます。
B. 強力なバックアップを備えたデータセンターを使用することによって。- 強力なバックアップはデータ保護に重要ですが、高可用性とリアルタイムの耐障害性を保証する主な方法ではありません。
C. 自動データ復旧手順を実装することによって。- 自動データ復旧手順は、障害発生後の復旧を迅速化しますが、高可用性と耐障害性を保証する主な方法ではありません。
D. 必須要員へのデータアクセスを制限することによって。- データアクセス制限は、セキュリティを向上させますが、高可用性と耐障害性には直接関係ありません。"
52,Data Cloudでアイデンティティ解決を設定する際、異なるデータソースからのレコードが同じ個人を表すかどうかを判断するためにマッチルールを定義します。メールアドレスや電話番号が完全に一致する場合にレコードを照合するルールタイプは、一般的に何と呼ばれますか？,ファジーマッチ,正規化ルール,再調整ルール,完全一致,D,"A. ファジーマッチ - ファジーマッチは、名前のスペルミスや住所の表記揺れなど、値が完全には一致しない場合でも、類似性に基づいてレコードを照合するためのルールです。
B. 正規化ルール - 正規化ルールは、マッチング処理の前に、電話番号の形式統一（例：ハイフンや括弧の削除）やメールアドレスの小文字化などを行い、データ表記を標準化するためのルールです。照合（マッチング）のルールそのものではありません。
C. 再調整ルール - 再調整ルールは、一度統合されたプロファイルに対して、後からより信頼性の高いデータが連携された場合などに、プロファイルの結合や分割を調整するために使用されるルールです。レコードを初期照合するためのルールではありません。
D. 完全一致 - 正解です。完全一致ルールは、メールアドレス、電話番号、顧客IDなど、一意性が高いとされる項目の値が完全に同じ場合に、異なるデータソースからのレコードを同一人物として照合するために使用される基本的なマッチルールタイプです。"
53,Cloud Kicksは、過去7日間にウェブサイトを訪問した顧客のセグメントを作成したいと考えています。エンゲージメント日付項目にどのフィルター演算子がこのユースケースに適合しますか？,期間内,過去の数より大きい,次の数日間,過去の日数,D,"A. 期間内 - 「期間内」演算子は、特定の日付範囲内のエンゲージメントをフィルタリングするために使用されます。このユースケースでは、特定の日付範囲ではなく、過去7日間をフィルタリングする必要があるため、適切ではありません。
B. 過去の数より大きい - 「過去の数より大きい」演算子は、特定の日数よりも古いエンゲージメントをフィルタリングするために使用されます。このユースケースでは、過去7日間のエンゲージメントをフィルタリングする必要があるため、適切ではありません。
C. 次の数日間 - 「次の数日間」演算子は、将来の特定の日数内のエンゲージメントをフィルタリングするために使用されます。このユースケースでは、過去7日間のエンゲージメントをフィルタリングする必要があるため、適切ではありません。
D. 過去の日数 - 正解です。「過去の日数」演算子は、過去の特定の日数内のエンゲージメントをフィルタリングするために使用されます。このユースケースでは、過去7日間のウェブサイト訪問をフィルタリングする必要があるため、この演算子が適切です。"
54,コンサルタントは、統合された個人プロファイルが最新のメールアドレスを保存していないことに気付きました。コンサルタントはこの問題をトラブルシューティングするためにどのようなアクションを取るべきですか？,Salesforce CRMから古いメールアドレスを削除します。,DLOオブジェクトのマッピングが取引先責任者電話メールに正しく行われているか確認します。,調整ルールが正しく使用されていることを確認します。,必要に応じて、ソースシステムでメールアドレスを確認および更新します。,C,"A. Salesforce CRMから古いメールアドレスを削除します。- Salesforce CRMから古いメールアドレスを削除することは、データ品質を向上させるのに役立ちますが、統合プロファイルが最新のメールアドレスを保存しない問題を直接解決するものではありません。
B. DLOオブジェクトのマッピングが取引先責任者電話メールに正しく行われているか確認します。- DLOオブジェクトのマッピングが正しいことは重要ですが、最新のメールアドレスが保存されない問題を解決するための主なトラブルシューティング手順ではありません。
C. 調整ルールが正しく使用されていることを確認します。- 正解です。統合プロファイルが最新のメールアドレスを保存しない主な原因は、調整ルールが正しく設定されていないことです。調整ルールは、複数のソースからのデータを統合する際に、どのデータを選択するかを決定します。調整ルールが古いデータを選択するように設定されている場合、最新のメールアドレスが保存されません。
D. 必要に応じて、ソースシステムでメールアドレスを確認および更新します。- ソースシステムでメールアドレスを確認および更新することは、データ品質を向上させるのに役立ちますが、統合プロファイルが最新のメールアドレスを保存しない問題を直接解決するものではありません。"
55,"コンサルタントが顧客のData Cloud組織で作業しており、既存のID解決ルールセットを削除するように求められています。コンサルタントは、このアクションの結果としてどのような2つの影響を伝えるべきですか？
2つの答えを選択してください。",すべての個人データが削除されます。,このルールセットに関連付けられた統合顧客データが削除されます。,データモデルオブジェクトの依存関係が削除されます。,すべてのソースプロファイルデータが削除されます。,"B,C","A. すべての個人データが削除されます。- ID解決ルールセットを削除しても、元の個人データは削除されません。削除されるのは、ルールセットに基づいて統合されたデータのみです。
B. このルールセットに関連付けられた統合顧客データが削除されます。- 正解です。ID解決ルールセットを削除すると、そのルールセットに基づいて統合された顧客データが削除されます。これは、統合されたプロファイルがルールセットに依存しているためです。
C. データモデルオブジェクトの依存関係が削除されます。- 正解です。ID解決ルールセットは、データモデルオブジェクト間の関係を定義します。ルールセットを削除すると、これらの依存関係が削除されます。
D. すべてのソースプロファイルデータが削除されます。- ID解決ルールセットを削除しても、元のソースプロファイルデータは削除されません。削除されるのは、ルールセットに基づいて統合されたデータのみです。"
56,"Northern Trail Outfittersは、Marketing CloudのデータをData Cloudに取り込むために、Marketing Cloudスターターデータバンドルを使用しています。Marketing Cloudスターターデータバンドルで利用可能な2つのデータセットは何ですか？

2つの答えを選択してください。",パーソナライゼーション,MobileConnect,ロイヤルティ管理,MobilePush,"B,D","A. パーソナライゼーション - パーソナライゼーションは、Marketing Cloudの機能であり、スターターデータバンドルに含まれるデータセットではありません。
B. MobileConnect - 正解です。MobileConnectは、SMSメッセージングデータをData Cloudに取り込むためのスターターデータバンドルに含まれるデータセットです。
C. ロイヤルティ管理 - ロイヤルティ管理は、Salesforce Loyalty Managementの機能であり、Marketing Cloudスターターデータバンドルには含まれていません。
D. MobilePush - 正解です。MobilePushは、モバイルプッシュ通知データをData Cloudに取り込むためのスターターデータバンドルに含まれるデータセットです。"
57,Data Cloudで効果的なデータモデリングを行うためには、いくつかのベストプラクティスに従うことが推奨されます。将来の拡張性や保守性を考慮したスキーマ設計を行う上で、コンサルタントが推奨すべきアプローチとして適切なものを2つ選択してください。（２つ選択）,可能な限り多くの項目を単一の巨大なデータモデルオブジェクト（DMO）にまとめる。,Salesforceが提供する標準データモデル（CIM）を活用し、可能な範囲で標準オブジェクトにマッピングする。,データソースオブジェクト（DSO）の項目名をそのままDMOの項目名として使用する。,データモデルオブジェクト（DMO）間のリレーションシップを適切に定義し、正規化を意識する。,"B,D","A. 可能な限り多くの項目を単一の巨大なデータモデルオブジェクト（DMO）にまとめる。 - 関連性の低い項目まで一つのDMOに詰め込むと、モデルが複雑化し、管理やメンテナンスが困難になります。また、パフォーマンスにも影響を与える可能性があります。適切な粒度でオブジェクトを分割することが推奨されます。

B. Salesforceが提供する標準データモデル（CIM）を活用し、可能な範囲で標準オブジェクトにマッピングする。 - 正解です。Cloud Information Model (CIM) は、様々なデータソース間で共通理解を促進するための標準データモデルです。可能な限りCIMに準拠した標準DMOにデータをマッピングすることで、Data Cloudの標準機能との連携がスムーズになり、将来的な拡張性やエコシステムとの互換性が高まります。

C. データソースオブジェクト（DSO）の項目名をそのままDMOの項目名として使用する。 - データソースによって項目名の命名規則は異なります。DSOの項目名をそのままDMOで使用すると、モデル全体で命名規則が不統一になり、理解しにくくなります。DMOでは、CIMのガイドラインに従うなど、一貫性のある分かりやすい命名規則を採用することがベストプラクティスです。

D. データモデルオブジェクト（DMO）間のリレーションシップを適切に定義し、正規化を意識する。 - 正解です。関連するデータを適切なDMOに分割し（データの正規化）、それらのDMO間をリレーションシップで正しく接続することは、データモデルの基本です。これにより、データの冗長性が最小限に抑えられ、データの一貫性が保たれ、将来的な変更にも柔軟に対応できるスケーラブルなモデルを構築できます。"
58,クライアントは、同じレコード内に蓄積されたホテルポイントと航空会社ポイントのポイント残高を含むSalesforce CRMのカスタムオブジェクトからロイヤルティデータを取り込みたいと考えています。クライアントは、より良い追跡と処理のために、これらのポイントシステムを2つの別々のレコードに分割したいと考えています。このシナリオでコンサルタントは何を推奨すべきですか？,データソースオブジェクトを複製します。,バッチ変換を使用して2番目のデータレイクオブジェクトを作成します。,Salesforce CRMに連結オブジェクトを作成し、取り込み戦略を変更します。,データレイクオブジェクトからデータキットを作成し、同じData Cloud組織にデプロイします。,B,"A. データソースオブジェクトを複製します。- データソースオブジェクトを複製しても、同じレコード内のポイントデータを分割することはできません。
B. バッチ変換を使用して2番目のデータレイクオブジェクトを作成します。- 正解です。バッチ変換を使用すると、元のデータレイクオブジェクトからデータを読み取り、必要な変換（この場合はポイントシステムの分割）を適用して、新しいデータレイクオブジェクトを作成できます。これにより、ポイントデータを2つの別々のレコードに分割できます。
C. Salesforce CRMに連結オブジェクトを作成し、取り込み戦略を変更します。- Salesforce CRMに連結オブジェクトを作成しても、Data Cloudでのデータ分割には直接的な影響はありません。取り込み戦略を変更しても、Data Cloudでのデータ変換は必要です。
D. データレイクオブジェクトからデータキットを作成し、同じData Cloud組織にデプロイします。- データキットは、データセット、セグメント、計算インサイトなどの再利用可能なコンポーネントのコレクションですが、レコード内のデータを分割する機能はありません。"
59,コンサルタントは、Interaction SDKまたはMobile SDKを介して収集されたデータに対して15分間のウィンドウで集計を実行する場合、どの方法を使用する必要がありますか？,バッチ変換,計算インサイト,ストリーミングインサイト,数式項目,C,"A. バッチ変換 - バッチ変換は、大量のデータをまとめて処理するために使用され、リアルタイムの集計には適していません。
B. 計算インサイト - 計算インサイトは、既存のデータに基づいて新しい計算されたディメンションまたはメトリックを作成するために使用されますが、リアルタイムの集計には適していません。
C. ストリーミングインサイト - 正解です。ストリーミングインサイトは、リアルタイムのデータストリームを監視し、指定された時間ウィンドウ内で集計を実行するために使用されます。15分間のウィンドウでの集計には、ストリーミングインサイトが最適です。
D. 数式項目 - 数式項目は、レコードが作成または更新されるときに値を計算するために使用されますが、リアルタイムの集計には適していません。"
60,Universal Containersは、Data Cloudへのアクセスを役割に応じて制御したいと考えています。マーケターにはセグメント作成とアクティベーションの権限を、データアナリストには計算済みインサイト作成の権限を、データエンジニアにはデータストリームとマッピング管理の権限を付与したいと考えています。これらの機能レベルのアクセス権をユーザーに割り当てるために使用される主要なメカニズムは何でしょうか？（２つ選択）,Data Cloudのロール,Data Cloud権限セット,プロファイル,共有ルール,"B,C","A. Data Cloudのロール - Salesforceにはロール階層がありますが、これは主にレコードアクセス権の継承に関連します。Data Cloudの特定の機能（例：セグメント作成、データストリーム管理）へのアクセス権は、主に権限セットによって制御されます。
B. Data Cloud権限セット - 正解です。Data Cloudの機能に対するアクセス権限は、専用の権限セット（標準で提供されるもの、またはカスタムで作成するもの）を通じてユーザーに付与されます。これにより、「セグメントを作成できる」「データストリームを管理できる」といった機能レベルのアクセスを役割に応じて細かく制御できます。
C. プロファイル - 正解です。プロファイルは、Salesforceプラットフォームにおける基本的なアクセス制御の仕組みであり、Data Cloudに関連するオブジェクト（データストリーム、データモデルオブジェクトなど）への基本的な参照・作成・編集・削除権限や、タブの表示設定などを決定します。権限セットは通常、プロファイルの権限に追加する形で機能アクセスを付与します。
D. 共有ルール - 共有ルールは、組織の共有設定（OWD）で制限されたレコードレベルのアクセス権を、特定のユーザーグループに対して拡張するためのものです。Data Cloudの機能を利用できるかどうかといった権限を制御するものではありません。"
61,"Northern Trail Outfittersは、Data Cloudインスタンス内の個人を統合します。コンサルタントは、統合プロファイルのデータを検証するために、どの3つの機能を使用できますか？
3つの答えを選択してください。",ID解決,Query APL,データエクスプローラー,プロファイルエクスプローラー,"A,C,D","A. ID解決 - 正解です。ID解決は、複数のソースからのデータを統合し、統一された個人プロファイルを作成するプロセスです。ID解決の結果を検証することで、統合が正しく行われているかを確認できます。
B. Query APL - Query APLは、Data Cloud内のデータに対してクエリを実行するための言語ですが、統合プロファイルのデータを検証するための主要なツールではありません。
C. データエクスプローラー - 正解です。データエクスプローラーは、Data Cloud内のデータを探索し、検証するためのツールです。統合された個人プロファイルに関連するデータを確認し、データの整合性を検証できます。
D. プロファイルエクスプローラー - 正解です。プロファイルエクスプローラーは、統合された個人プロファイルの詳細を表示し、検証するためのツールです。統合されたプロファイルの属性や関連データを確認し、データの正確性を検証できます。
E. データアクション - データアクションは、Data Cloud内のデータに基づいてアクションを実行するための機能であり、統合プロファイルのデータを検証するためのツールではありません。"
62,Data Cloudにおける人工知能（AI）の役割は何ですか？,データ検証の自動化,動的なデータ駆動型管理ダッシュボードの作成,インサイトと予測を通じて顧客とのやり取りを強化する,ユースケースで使用するためのメールテンプレートの生成,C,"A. データ検証の自動化 - AIはデータ検証を自動化するのに役立ちますが、Data CloudにおけるAIの主な役割ではありません。
B. 動的なデータ駆動型管理ダッシュボードの作成 - AIはダッシュボードの作成を支援できますが、Data CloudにおけるAIの主な役割ではありません。
C. インサイトと予測を通じて顧客とのやり取りを強化する - 正解です。Data CloudにおけるAIの主な役割は、顧客データを分析し、インサイトと予測を生成することで、顧客とのやり取りを強化することです。これにより、企業は顧客をより深く理解し、パーソナライズされた体験を提供できます。
D. ユースケースで使用するためのメールテンプレートの生成 - AIはメールテンプレートの生成を支援できますが、Data CloudにおけるAIの主な役割ではありません。"
63,Salesforce Data Cloudのセットアップと管理において、システムへのアクセス制御とデータの安全性を確保するために考慮すべき重要な要素を2つ選択してください。,データストリームの作成時に、データソースの認証情報を個々のユーザーアカウントに紐付ける。,ユーザーの職務と責任に基づいて、適切な権限セットを割り当てる。,定期的に監査ログを確認し、不審なアクティビティがないか監視する。,データレイクオブジェクトへのアクセス権限は、すべてのユーザーに対して読み取り専用とする。,"B,C","A. データストリームの作成時に、データソースの認証情報を個々のユーザーアカウントに紐付ける - データソースの認証情報を個々のユーザーアカウントに紐付けることは、管理の複雑性を増し、セキュリティ上のリスクを高める可能性があります。通常は、より集中管理された方法で認証情報を管理します。

B. ユーザーの職務と責任に基づいて、適切な権限セットを割り当てる - 正解です。最小権限の原則に従い、ユーザーにはその職務遂行に必要な最小限の権限のみを付与することが、アクセス制御とセキュリティのベストプラクティスです。権限セットを活用することで、役割に応じたアクセス管理が可能になります。

C. 定期的に監査ログを確認し、不審なアクティビティがないか監視する - 正解です。監査ログの定期的な確認は、不正アクセスやセキュリティ侵害の兆候を早期に発見し、対応するために不可欠です。不審なアクティビティを監視することで、データセキュリティを維持することができます。

D. データレイクオブジェクトへのアクセス権限は、すべてのユーザーに対して読み取り専用とする - データレイクオブジェクトへのアクセス権限を一律に読み取り専用とすることは、データ活用の柔軟性を損なう可能性があります。ユーザーの役割や業務ニーズに応じて、適切なアクセス権限（読み取り、書き込みなど）を付与する必要があります。"
64,Universal Containersは、Data Cloudを導入し、パーソナライズされたマーケティングキャンペーンを実施した結果、その投資対効果（ROI）を測定したいと考えています。Data Cloudのデータを活用してキャンペーンのビジネス成果を評価する際に、コンサルタントが分析・比較すべき指標の組み合わせとして最も適切なものはどれでしょうか？,データストリームの処理時間とデータストレージ使用量,アイデンティティ解決のマッチ率と調整ルールの数,キャンペーン対象セグメントのコンバージョン率と非対象グループのコンバージョン率,Data Cloudライセンス費用と導入プロジェクトにかかった工数,C,"A. データストリームの処理時間とデータストレージ使用量 - これらはData Cloudシステムの運用効率やコストに関する指標ですが、実施したマーケティングキャンペーンがビジネス目標（売上向上、顧客獲得など）にどれだけ貢献したかを直接示すものではありません。

B. アイデンティティ解決のマッチ率と調整ルールの数 - これらはData Cloud内のデータ統合プロセスの健全性や設定状況を示す指標ですが、キャンペーンの成果を評価するための指標ではありません。

C. キャンペーン対象セグメントのコンバージョン率と非対象グループのコンバージョン率 - 正解です。キャンペーンの真の効果を測定するためには、キャンペーンの対象となったセグメントにおける成果（例：購入率、申込率などのコンバージョン率）と、キャンペーンに接触しなかった比較対象グループ（コントロールグループなど）のコンバージョン率を比較することが重要です。この差（リフト）を見ることで、キャンペーンがビジネス成果に与えた純粋な影響を評価できます。

D. Data Cloudライセンス費用と導入プロジェクトにかかった工数 - これらはキャンペーン実施のための投資（コスト）側の要素であり、キャンペーンによって得られた成果（リターン）ではありません。ROIを計算する際には考慮されますが、成果を測定する指標自体ではありません。"
65,コンサルタントは、複数のばらばらのデータソースを持つ顧客とData Cloudの利点について話し合っています。顧客データの管理に関して、コンサルタントはどの2つの機能領域を強調すべきですか？2つ選択してください。,データハーモナイゼーション,統一プロファイル,マスターデータ管理,データマーケットプレイス,"A,B","A. データハーモナイゼーション - 正解です。データハーモナイゼーションは、異なるデータソースからのデータを統一された形式に変換し、整合性を保つプロセスです。複数のばらばらのデータソースを持つ顧客にとって、データの整合性を確保し、分析や活用を容易にするために重要な機能です。
B. 統一プロファイル - 正解です。統一プロファイルは、複数のデータソースからの顧客データを統合し、単一の顧客ビューを作成する機能です。これにより、顧客の全体像を把握し、よりパーソナライズされた顧客体験を提供できます。
C. マスターデータ管理 - マスターデータ管理（MDM）は、組織全体の重要なデータ（顧客、製品など）の一貫性と正確性を確保するためのプロセスです。Data CloudはMDM機能を提供しますが、顧客データの管理という観点では、データハーモナイゼーションと統一プロファイルの方が直接的な利点となります。
D. データマーケットプレイス - データマーケットプレイスは、外部データソースからのデータを購入または共有するためのプラットフォームです。これはデータ統合や顧客プロファイルの管理とは異なる機能であり、顧客データの管理という観点では優先度が低いです。"
66,Data Cloudで外部ソースからデータを取り込み、アイデンティティ解決やセグメンテーションで利用できるように準備する過程において、「データソースオブジェクト（DSO）」と「データモデルオブジェクト（DMO）」は重要な役割を果たします。DSOからDMOへのデータの流れとして、最も適切な説明はどれでしょうか？,DMOのデータがDSOにマッピングされ、データソースに書き戻される。,DSOに取り込まれた元データが、標準またはカスタムのDMO構造にマッピングされ、正規化される。,DSOはDMOから計算されたインサイトを格納するために使用される。,DMOはデータストリーム設定で直接データソースに接続される。,B,"A. DMOのデータがDSOにマッピングされ、データソースに書き戻される。 - データソースオブジェクト(DSO)はデータソースから取り込んだ生のデータを保持し、データモデルオブジェクト(DMO)は正規化されたデータを保持します。データの流れはこの逆であり、DMOからDSOへのマッピングやデータソースへの書き戻しは通常の取り込みプロセスではありません。
B. DSOに取り込まれた元データが、標準またはカスタムのDMO構造にマッピングされ、正規化される。 - 正解です。データはまずデータストリームを通じてデータソースオブジェクト(DSO)に取り込まれます。DSOはデータソースのスキーマを反映します。次に、このDSOの項目が、Salesforceが提供する標準的なデータモデル(CIM - Cloud Information Model)に基づいたデータモデルオブジェクト(DMO)やカスタムDMOの項目にマッピングされます。このプロセスを通じてデータは正規化され、Data Cloud内で統一的に扱えるようになります。
C. DSOはDMOから計算されたインサイトを格納するために使用される。 - 計算済みインサイトはDMOのデータに基づいて計算されますが、その結果を格納するのはDSOではありません。DSOはデータソースから取り込んだデータを格納します。
D. DMOはデータストリーム設定で直接データソースに接続される。 - データストリームはデータソースとデータソースオブジェクト(DSO)を接続します。DSOからDMOへのマッピングはデータストリームの設定の一部ですが、DMOが直接データソースに接続されるわけではありません。"
67,Northern Trail OutfittersはData Cloudの実装を検討しており、いくつかのユースケースを想定しています。Data Cloudに適したユースケースはどれですか？2つ選択してください。,様々なソースからデータを取り込み、統合して顧客IDを調整する。,クロスチャネルマーケティングメッセージを作成および調整する。,調整されたデータを使用して、顧客とビジネスへの影響をより正確に理解する。,個別のビジネスインテリジェンスおよびITデータ管理ツールを不要にする。,"A,C","A. 様々なソースからデータを取り込み、統合して顧客IDを調整する - 正解です。Data Cloudは、異なるデータソースからのデータを統合し、顧客の統一プロファイルを作成する機能に優れています。これはID解決の主要な目的であり、Data Cloudの重要なユースケースです。
B. クロスチャネルマーケティングメッセージを作成および調整する - Data Cloudはデータ統合と顧客インサイトに重点を置いており、直接的なマーケティングメッセージの作成や調整は主な機能ではありません。マーケティング自動化ツール（Marketing Cloudなど）がこの用途に適しています。
C. 調整されたデータを使用して、顧客とビジネスへの影響をより正確に理解する - 正解です。Data Cloudは、統合されたデータを使用して顧客の行動や傾向を分析し、ビジネス上の意思決定を支援します。これはData Cloudの主要な目的の一つです。
D. 個別のビジネスインテリジェンスおよびITデータ管理ツールを不要にする - Data Cloudはデータ統合と顧客インサイトに特化しており、全てのビジネスインテリジェンスやITデータ管理ツールを置き換えるわけではありません。これらのツールはそれぞれ異なる目的と機能を持っています。"
68,ある企業が、顧客データを様々なシステム（CRM、マーケティング、Eコマース、サービス）に分散して保持しており、顧客一人ひとりに対する一貫した理解や体験の提供に課題を抱えています。Salesforce Data Cloudを導入する主な目的として、この課題に対して最も貢献することは何でしょうか？,分散した顧客データを統合し、単一の顧客ビュー（統合プロファイル）を構築する。,各部門のレポート作成プロセスを個別に最適化する。,"リアルタイムのWebサイトトラフィック監視機能を提供する。
 D. 企業の財務会計システムを置き換える。",企業の財務会計システムを置き換える。,A,"A. 分散した顧客データを統合し、単一の顧客ビュー（統合プロファイル）を構築する。 - 正解です。Data Cloudの最も重要な目的の一つは、企業内に散在する様々なソースからの顧客データを収集・統合し、アイデンティティ解決を通じて「単一の信頼できる顧客像（Single Source of Truth）」、すなわち統合プロファイルを構築することです。これにより、顧客をより深く理解し、一貫性のあるパーソナライズされた体験を提供することが可能になります。
B. 各部門のレポート作成プロセスを個別に最適化する。 - Data Cloudは統合されたデータを提供することで部門横断的な分析やレポート作成を支援しますが、各部門の既存のレポートプロセスを個別に最適化することが主目的ではありません。
C. リアルタイムのWebサイトトラフィック監視機能を提供する。 - Data CloudはWebサイトからのイベントデータを取り込み、顧客行動の分析に活用できますが、Webサイトのトラフィックをリアルタイムで詳細に監視するための専用ツール（例：アクセス解析ツール）ではありません。
D. 企業の財務会計システムを置き換える。 - Data Cloudは顧客データに特化したプラットフォーム（CDP）であり、売上データなどを取り込むことはあっても、企業の財務会計処理を行うためのシステムではありません。"
69,"Northern Trail Outfittersは毎日、過去24時間の店舗取引の概要をAmazon S3バケット内の新しいファイルにアップロードし、7日より古いファイルは自動的に削除されます。各ファイルには、標準化された命名規則でタイムスタンプが含まれています。
コンサルタントは、このデータストリームを取り込む際に、どの2つのオプションを設定する必要がありますか？

2つの回答を選択してください。",古いファイルの削除が有効になっていることを確認します。,更新モードが「Upsert」に設定されていることを確認します。,ファイル名にタイムスタンプに対応するためのワイルドカードが含まれていることを確認します。,更新モードが「完全更新」に設定されていることを確認します。,"B,C","A. 古いファイルの削除が有効になっていることを確認します。 - ファイルの削除はデータソース側（Amazon S3）で行われる設定であり、データ取り込み側の設定ではありません。したがって、これはData Cloudの設定としては不適切です。
B. 更新モードが「Upsert」に設定されていることを確認します。 - 正解です。毎日新しいファイルがアップロードされるため、既存のデータを更新（Upsert）する必要があります。完全更新（Full Refresh）では、毎回すべてのデータが再取り込みされるため、効率が悪いです。
C. ファイル名にタイムスタンプに対応するためのワイルドカードが含まれていることを確認します。 - 正解です。ファイル名にタイムスタンプが含まれているため、ワイルドカードを使用して、毎日異なるファイル名を正しく認識し、データを取り込む必要があります。
D. 更新モードが「完全更新」に設定されていることを確認します。 - 完全更新（Full Refresh）は、毎回すべてのデータを再取り込みするため、データの量が多い場合には効率が悪くなります。今回のケースでは、毎日更新されるデータのみを取り込む「Upsert」が適切です。"
70,"Northern Trail Outfittersは、各顧客の生涯価値（LTV）を計算し、ウェブサイト、モバイルアプリ、小売チャネルごとの収益の内訳を作成したいと考えています。
コンサルタントは、Data Cloudでこのユースケースに対応するために何を使用すべきでしょうか？",フローオーケストレーション,ネストされたセグメント,メトリクスのメトリクス,ストリーミングデータ変換,C,"A. フローオーケストレーション - フローオーケストレーションは、複数のステップからなる複雑なビジネスプロセスを自動化するためのツールです。LTVの計算や収益の内訳作成には直接関係しません。
B. ネストされたセグメント - ネストされたセグメントは、より複雑な顧客セグメントを作成するために使用されます。LTVの計算には使用されますが、チャネルごとの収益の内訳を作成する機能は提供しません。
C. メトリクスのメトリクス - 正解です。メトリクスのメトリクスは、既存のメトリクス（例えば、総収益）に基づいて新しいメトリクス（例えば、チャネルごとの収益）を計算する機能です。これにより、LTVを計算し、さらにチャネルごとの収益の内訳を作成することが可能になります。
D. ストリーミングデータ変換 - ストリーミングデータ変換は、リアルタイムでデータを変換し、処理するためのツールです。LTVの計算や収益の内訳作成は、ストリーミングデータ変換よりも、集計されたデータに対して行うメトリクスのメトリクスの方が適しています。"
71,Universal Containersは、Data Cloudに取り込んだ自社の顧客データ（ファーストパーティデータ）に加えて、外部のデータプロバイダーから提供されるデモグラフィック情報や興味関心データ（サードパーティデータ）を利用して、顧客プロファイルをより豊かにしたいと考えています。このプロセスは一般的に何と呼ばれますか？,データエンリッチメント (Data Enrichment),データクレンジング (Data Cleansing),データマスキング (Data Masking),データアーカイブ (Data Archiving),A,"A. データエンリッチメント (Data Enrichment) - 正解です。データエンリッチメントは、企業が保有する既存の顧客データ（ファーストパーティデータ）に対して、外部の信頼できるデータソース（サードパーティデータプロバイダーなど）から提供される追加情報を付加するプロセスです。これにより、顧客のデモグラフィック情報、興味関心、ライフスタイルなどの理解を深め、プロファイルの価値を高めることができます。

B. データクレンジング (Data Cleansing) - データクレンジングは、データセット内の不正確な、不完全な、または無関係な部分を検出して修正または削除するプロセスであり、データの品質向上を目的とします。外部からデータを追加するエンリッチメントとは異なります。

C. データマスキング (Data Masking) - データマスキングは、データの構造を維持しながら、機密性の高い元のデータを架空の（ただし現実的な）データに置き換えるプロセスです。主に、テスト環境などで本番データを使用する際のプライバシー保護のために行われます。

D. データアーカイブ (Data Archiving) - データアーカイブは、アクティブには使用されなくなったが、規制遵守や将来の参照のために保持する必要があるデータを、主要な運用データベースから別の長期保管場所に移動するプロセスです。"
72,"ある企業が、異なるターゲット層に対してマーケティングキャンペーンをテストしたいと考えています。
異なるターゲット層を取得するために、コンサルタントはセグメントキャンバスインターフェースで何を調整する必要がありますか？",直接属性、関連属性、および人口フィルター,セグメントフィルター、直接属性、およびデータソース,直接属性および関連属性,人口フィルターおよび直接属性,A,"A. 直接属性、関連属性、および人口フィルター - 正解です。セグメントキャンバスでは、直接属性（顧客の年齢、性別など）、関連属性（購入履歴、閲覧履歴など）、および人口フィルター（特定の条件を満たす顧客のみを抽出）を調整することで、異なるターゲット層を作成できます。
B. セグメントフィルター、直接属性、およびデータソース - データソースはセグメントを作成する上での基盤となる物です。セグメントフィルターは、人口フィルターとほぼ同義です。セグメントを作成する上で、関連属性は重要な要素です。
C. 直接属性および関連属性 - 直接属性と関連属性だけでもセグメントを作成する事はできますが、人口フィルターを調整する事で、より詳細なセグメントを作成する事が可能です。
D. 人口フィルターおよび直接属性 - 人口フィルターと直接属性だけでもセグメントを作成する事はできますが、関連属性を調整する事で、より詳細なセグメントを作成する事が可能です。"
73,Data Cloudでデータモデリングを行う際、データソースオブジェクト(DSO)のデータをデータモデルオブジェクト(DMO)にマッピングします。DSO内の各レコードを一意に識別するための項目（例：顧客ID、注文ID）は、DMOにマッピングされる際に通常どのように扱われますか？,メジャー項目として扱われる。,リレーションシップ項目として扱われる。,主キー (Primary Key) または外部キー (Foreign Key) として機能する項目としてマッピングされる。,数式項目として再計算される。,C,"A. メジャー項目として扱われる。 - 主キーはレコードを一意に識別するためのものであり、通常は集計や計算の対象となる測定可能な値（メジャー）ではありません。ディメンションとして扱われることが一般的です。

B. リレーションシップ項目として扱われる。 - リレーションシップ項目は、あるDMOから別のDMOへの参照を保持するために使用されます。主キーはレコード自体の識別子であり、リレーションシップ項目とは異なります（ただし、外部キーとしてリレーションに使用されることはあります）。

C. 主キー (Primary Key) または外部キー (Foreign Key) として機能する項目としてマッピングされる。 - 正解です。データソースオブジェクト(DSO)内でレコードを一意に示すキー項目は、データモデルオブジェクト(DMO)にマッピングされる際に、そのDMOの主キーとして設定されたり、他のDMOとの関連付けを定義するための外部キーとして利用されたりします。これにより、データの整合性維持やリレーションシップ構築が可能になります。

D. 数式項目として再計算される。 - 主キーは通常、データソースシステムで割り当てられた一意の値であり、Data Cloudのデータマッピングプロセス中に数式で再計算される性質のものではありません。"
74,"コンサルタントがエンゲージメントベースの関連属性を使用した最近のアクティベーションを確認していますが、セグメントメンバーの大部分のペイロードに関連属性が表示されません。
この問題をトラブルシューティングするために、コンサルタントはどの2つの領域を確認する必要がありますか？
2つの回答を選択してください。",関連するエンゲージメントイベントが過去90日以内に発生した。,アクティベーションが、エンゲージメントデータではなくプロファイルデータをセグメント化するセグメントを参照している。,関連属性に正しいパスが選択されている。,アクティブ化されたプロファイルに統合取引先責任者ポイントがある。,"A,C","A. 関連するエンゲージメントイベントが過去90日以内に発生した。 - 正解です。エンゲージメントベースの関連属性は、通常、特定の期間（例えば、過去90日間）内に発生したイベントに基づいています。したがって、関連するイベントがこの期間外に発生した場合、属性はペイロードに含まれません。
B. アクティベーションが、エンゲージメントデータではなくプロファイルデータをセグメント化するセグメントを参照している。 - プロファイルデータに基づくセグメント化は、エンゲージメントベースの関連属性とは直接関係ありません。問題は、エンゲージメントベースの関連属性がペイロードに表示されないことであるため、この選択肢は適切ではありません。
C. 関連属性に正しいパスが選択されている。 - 正解です。関連属性を正しく取得するには、データモデル内で正しいパス（関連エンゲージメントイベントへの参照）が選択されている必要があります。パスが間違っている場合、関連属性はペイロードに表示されません。
D. アクティブ化されたプロファイルに統合取引先責任者ポイントがある。 - 統合取引先責任者ポイントは、プロファイルの統合に使用されますが、エンゲージメントベースの関連属性の表示には直接影響しません。"
75,: Universal Containersは、Data Cloudで「過去6ヶ月間に高額商品を購入したロイヤル顧客」というセグメントを作成しました。このセグメントに対して、Marketing Cloud Engagementでパーソナライズされたメールキャンペーンを実施したいと考えています。作成したData CloudセグメントをMarketing Cloud Engagementで利用できるようにするための主要なプロセスは何でしょうか？,データストリームの設定,計算済みインサイトの作成,アクティベーションの設定,アイデンティティ解決ルールの調整,C,"A. データストリームの設定 - データストリームは、外部ソースからData Cloudへデータを取り込むためのプロセスです。Data Cloudから外部システムへセグメント情報を送信するプロセスではありません。
B. 計算済みインサイトの作成 - 計算済みインサイトは、Data Cloud内のデータに基づいて顧客に関する指標や属性を計算する機能です。セグメントを他のシステムで利用可能にするためのプロセスではありません。
C. アクティベーションの設定 - 正解です。アクティベーションは、Data Cloudで作成されたセグメント（または計算済みインサイトなどの他のデータ）を、Marketing Cloud Engagement、Sales Cloud、広告プラットフォームなどの外部システム（アクティベーションターゲット）に送信し、マーケティングキャンペーンやその他のアクションを実行できるようにするプロセスです。
D. アイデンティティ解決ルールの調整 - アイデンティティ解決ルールは、異なるデータソースからの顧客レコードを照合し、統合プロファイルを作成するためのルールです。作成されたセグメントを外部システムに連携させるプロセスではありません。"
76,"Data Cloudコンサルタントが、企業のData Cloudライフサイクルの初期フェーズを評価しています。
Data Cloudライフサイクルを効果的に開始するために不可欠なアクションは何ですか？",ユースケースと必要なデータソースおよびデータ品質を特定する。,データを分析し、データスペースに分割する。,既存のデータをCustomer 360データモデルに移行する。,計算済みインサイトを使用して、この企業におけるData Cloudの利点を判断する。,A,"A. ユースケースと必要なデータソースおよびデータ品質を特定する。 - 正解です。Data Cloudライフサイクルの初期フェーズでは、まずビジネスのユースケースを明確にし、それに基づいて必要なデータソースとデータ品質を特定することが最も重要です。これにより、プロジェクトの方向性が定まり、後のフェーズがスムーズに進みます。
B. データを分析し、データスペースに分割する。 - データスペースへの分割は、データソースとユースケースを特定した後に行うべき作業です。初期フェーズでは、データの全体像を把握することが優先されます。
C. 既存のデータをCustomer 360データモデルに移行する。 - データ移行は、ユースケースとデータソースが特定され、データモデルが設計された後に行うべき作業です。初期フェーズでは、データの準備よりも計画が優先されます。
D. 計算済みインサイトを使用して、この企業におけるData Cloudの利点を判断する。 - 計算済みインサイトは、データが統合された後に利用できる機能です。初期フェーズでは、データの統合よりもユースケースの特定が優先されます。"
77,"アウトドアライフスタイル衣料品ブランドのNorthern Trail Outfitters（NTO）は、最近新しい事業ラインを開始しました。新しい事業は、グルメキャンプ食品を専門としています。ビジネス上の理由とセキュリティ上の理由から、NTOにとってすべてのData Cloudデータをブランドごとに分離しておくことが重要です。
ブランドごとにデータを分離したいというNTOの要望を最もよくサポートする機能はどれですか？",ブランドごとのデータストリーム,ブランドごとのデータモデルオブジェクト,ブランドごとのデータスペース,ブランドごとのデータソース,C,"A. ブランドごとのデータストリーム - データストリームは、データの取り込みに使用されますが、データの分離には直接関係しません。
B. ブランドごとのデータモデルオブジェクト - データモデルオブジェクトは、データの構造を定義しますが、データの分離には直接関係しません。
C. ブランドごとのデータスペース - 正解です。データスペースは、Data Cloud内のデータを論理的に分離するための機能です。ブランドごとにデータスペースを作成することで、データを完全に分離し、セキュリティとビジネス上の要件を満たすことができます。
D. ブランドごとのデータソース - データソースは、データの取得元を定義しますが、データの分離には直接関係しません。"
78,Universal Containersは、Data Cloudで統合された顧客プロファイルデータを使用して、特定のマーケティングキャンペーンのターゲットとなる顧客グループ（セグメント）を作成したいと考えています。Data Cloudでセグメントを作成する際に、コンサルタントが考慮すべき、または利用できる主要な機能や概念として適切なものを2つ選択してください。（２つ選択）,属性、関連属性、および行動データに基づいてフィルタリング条件を定義する。 B. セグメントに含める顧客プロファイルの最大数を設定する。,セグメントに含める顧客プロファイルの最大数を設定する。,作成したセグメントを他のシステムで利用するためにアクティベーションを設定する。,セグメント化の対象となるデータモデルオブジェクト（DMO）を選択する。,"A,D","A. 属性、関連属性、および行動データに基づいてフィルタリング条件を定義する。 - 正解です。Data Cloudのセグメンテーション機能では、統合プロファイルが持つ直接的な属性（例：年齢、性別、居住地）だけでなく、関連するオブジェクトの情報（例：過去の購入製品、ケース履歴）や、Webサイトの閲覧履歴、メールの開封・クリックといった行動データを利用して、複雑なフィルタリング条件を定義することができます。
B. セグメントに含める顧客プロファイルの最大数を設定する。 - セグメントのサイズ（含まれるプロファイル数）は設定したフィルタリング条件によって動的に決まります。通常、セグメント作成時にプロファイル数の上限を事前に設定する機能はありません。
C. 作成したセグメントを他のシステムで利用するためにアクティベーションを設定する。 - アクティベーションは、作成したセグメントをMarketing Cloud Engagementや他の連携システムに送信し、実際のマーケティング活動などで利用可能にするためのプロセスです。セグメントを作成する際の機能や概念そのものではありません。
D. セグメント化の対象となるデータモデルオブジェクト（DMO）を選択する。 - 正解です。セグメントを作成する際には、まずどのデータモデルオブジェクト（通常は統合個人プロファイルなど）を基準にするかを選択します。選択したDMOとその関連オブジェクトに含まれる項目を使って、セグメントのフィルタリング条件を構築します。"
79,Universal Containersは、CRM、Webサイト、モバイルアプリなど、複数のソースから収集した顧客データを持っています。これらの異なるソースからのレコードが同じ個人を表している可能性があり、Data Cloudでこれらを特定し、単一の統合された顧客プロファイルを作成する必要があります。このプロセスを実現するData Cloudの主要な機能は何でしょうか？,データ変換,セグメンテーション,アクティベーションターゲット,アイデンティティ解決,D,"A. データ変換 - データ変換は、データストリームを通じてData Cloudに取り込まれるデータの形式や値を標準化、クレンジングするプロセスの一部です。異なるレコードが同じ個人を表すかを特定し統合する機能ではありません。
B. セグメンテーション - セグメンテーションは、アイデンティティ解決によって作成された統合プロファイルに対して、特定の属性や行動履歴に基づいて顧客グループを作成するプロセスです。レコードの統合自体を行うものではありません。
C. アクティベーションターゲット - アクティベーションターゲットは、Data Cloudで作成したセグメントなどのデータを連携する外部システム（例：Marketing Cloud Engagement、広告プラットフォーム）を定義する設定です。顧客データの統合プロセスとは関係ありません。
D. アイデンティティ解決 - 正解です。アイデンティティ解決は、Data Cloudの中核機能の一つであり、事前に定義されたマッチルール（例：完全一致、ファジー一致）と調整ルールを用いて、異なるデータソースから取り込まれた個人のレコードを照合・特定し、それらを単一の統合プロファイルにまとめるプロセスです。これにより、顧客の包括的なビューを作成します。"
80,Universal Containersは、Salesforce CRM、マーケティングオートメーションツール、および外部のEコマースプラットフォームから顧客データをData Cloudに取り込みたいと考えています。これらの異なるソースからData Cloudへデータを継続的に連携させるための基本的な構成要素は何でしょうか？,計算済みインサイト,データストリーム,セグメント,アクティベーション,B,"A. 計算済みインサイト - 計算済みインサイトは、Data Cloudに取り込まれ、モデル化されたデータを使用して、顧客に関する集計値や指標（例：生涯価値、エンゲージメントスコア）を計算する機能です。データソースからデータを取り込むためのものではありません。

B. データストリーム - 正解です。データストリームは、様々なデータソース（Salesforce CRM、外部データベース、Webサイト、モバイルアプリなど）からData Cloudへデータを継続的に取り込むための接続と設定を表します。データソースとの連携、データの取り込みスケジュール、初期マッピングなどを定義します。

C. セグメント - セグメントは、Data Cloud内の統合された顧客プロファイルに対して、特定の属性や行動に基づいてターゲットグループを作成する機能です。データの取り込みを行うものではありません。

D. アクティベーション - アクティベーションは、Data Cloudで作成したセグメントやインサイトを、Marketing Cloud Engagement、Sales Cloud、外部広告プラットフォームなどの他のシステムに送信し、マーケティングキャンペーンやパーソナライズされた体験を提供するためにデータを「活用」するプロセスです。データの取り込みとは逆のプロセスです。"
81,Data Cloudにおいて、異なるデータソースから取り込んだ顧客データを統合個人プロファイルにまとめるプロセスで、どのレコードの項目値を最終的な統合プロファイルに残すかを決定するルールは何ですか？,データ変換ルール,一致ルール,調整ルール,セグメンテーションルール,C,"A. データ変換ルール - データ変換ルールは、データストリームを使用してデータを取り込む際に、ソースデータの形式や値をData Cloudのデータモデルに合わせて変換するために使用されます。プロファイルの項目値を決定する調整プロセスとは異なります。

B. 一致ルール - 一致ルールは、異なるデータソースからのレコードが同一の個人を表しているかどうかを識別するために使用されます。どの項目値を統合プロファイルに残すかを決定するルールではありません。

C. 調整ルール - 正解です。調整ルールは、ID解決プロセスにおいて、複数のソースレコードが同一の個人として一致した場合に、どのソースレコードのどの項目値を最終的な統合個人プロファイルに採用するかを決定するためのルールです。例えば、「最終更新日が最も新しいレコードのメールアドレスを採用する」といった設定が可能です。

D. セグメンテーションルール - セグメンテーションルールは、統合されたプロファイルデータを使用して、特定の条件に基づいて顧客グループ（セグメント）を作成するために使用されます。ID解決時の項目値選択プロセスとは直接関係ありません。"
82,企業がData Cloudを使用して、Webサイトでの匿名訪問者の行動データと、CRMシステム内の既知の顧客データを結び付けたいと考えています。このプロセスにおいて、Data Cloudが匿名プロファイルと既知のプロファイルを効果的にリンクさせるために利用する主要なメカニズムは何ですか？,データレークへの直接接続,ファーストパーティCookieとID解決,アクティベーションターゲットの設定,予測インサイトモデル,B,"A. データレークへの直接接続 - データレークへの接続はデータ収集の一環ですが、匿名プロファイルと既知プロファイルを直接結びつける主要なメカニズムではありません。データレークからデータを取り込んだ後、別途ID解決プロセスが必要です。

B. ファーストパーティCookieとID解決 - 正解です。Webサイトでの匿名訪問者の行動は、ファーストパーティCookieなどによって追跡されます。訪問者が後にログインやフォーム送信などで身元を明かすと、Data CloudのID解決プロセスがその情報（例: メールアドレス）を使用して、匿名時の行動データとCRM内の既知の顧客プロファイルを照合し、リンクさせます。

C. アクティベーションターゲットの設定 - アクティベーションターゲットは、Data Cloudで処理・統合されたデータを外部システム（例: マーケティングツール）に連携するための設定であり、匿名プロファイルと既知プロファイルを結びつけるプロセス自体ではありません。

D. 予測インサイトモデル - 予測インサイトモデルは、既存のデータに基づいて将来の行動や傾向を予測するために使用されます（例: 解約予測）。匿名プロファイルと既知プロファイルの基本的なリンク付けを行うメカニズムではありません。"
83,Data Cloudのセグメンテーション機能を利用して、特定の条件を満たす顧客グループを作成する際に、考慮すべき主要な要素や機能はどれですか？（2つ選択）,データストリームの取り込み頻度,セグメントの属性ライブラリの活用,ID解決の一致ルールの設定,セグメント化の対象となるデータモデルオブジェクト（DMO）の選択,"B,D","A. データストリームの取り込み頻度 - データストリームの取り込み頻度は、データの鮮度に影響しますが、セグメントを作成する際の条件設定や対象データ選択のプロセス自体に直接関わる主要な要素ではありません。

B. セグメントの属性ライブラリの活用 - 正解です。属性ライブラリには、セグメントの条件として利用可能な、関連付けられたDMOの項目（属性）が含まれています。セグメントを作成する際には、このライブラリから適切な属性を選択し、条件を定義します。

C. ID解決の一致ルールの設定 - ID解決の一致ルールは、異なるソースからのデータを統合して統一プロファイルを形成するプロセスで使用されます。セグメント作成の段階では、既に統合されたデータを利用するため、一致ルールの設定自体はセグメント作成時の直接的な要素ではありません。

D. セグメント化の対象となるデータモデルオブジェクト（DMO）の選択 - 正解です。セグメントを作成する最初のステップとして、どのDMO（例えば、統合個人や統合アカウントなど）に含まれるデータを対象とするかを選択する必要があります。これにより、セグメント化の基盤となるデータセットが決まります。"
84,Data Cloudに接続されたシステム間でデータの整合性を保ち、最新の顧客情報を反映させるために、データストリームの更新をどのようにスケジュールするのが一般的なベストプラクティスと考えられますか？,すべてのデータストリームをリアルタイムで更新する,データソースの変更頻度とビジネス要件に基づいて更新スケジュールを決定する,1日に1回、深夜にすべてのデータストリームを一括で更新する,主要な取引先責任者データのみ頻繁に更新し、他のデータは週次で更新する,B,"A. すべてのデータストリームをリアルタイムで更新する - リアルタイム更新は一部のユースケース（例：Webサイト行動追跡）では有効ですが、すべてのデータソースに適しているわけではなく、システム負荷やコストの観点から現実的でない場合があります。

B. データソースの変更頻度とビジネス要件に基づいて更新スケジュールを決定する - 正解です。各データソースのデータがどのくらいの頻度で変更されるか、そしてそのデータがビジネスプロセス（例: セグメンテーション、アクティベーション）でどの程度の鮮度を要求されるかを考慮して、データストリームごとに最適な更新頻度（リアルタイム、ニアリアルタイム、バッチスケジュール）を決定するのがベストプラクティスです。

C. 1日に1回、深夜にすべてのデータストリームを一括で更新する - この方法はシンプルですが、日中の重要なデータ変更が翌日まで反映されない可能性があり、データの鮮度が求められるユースケースには適さない場合があります。また、データソースによってはより頻繁な更新が必要な場合もあります。

D. 主要な取引先責任者データのみ頻繁に更新し、他のデータは週次で更新する - データの重要度に応じて更新頻度を変えるアプローチは合理的ですが、「主要な取引先責任者データ」という限定的な条件や「週次」といった固定的な頻度が、必ずしもすべてのビジネス要件を満たすとは限りません。より柔軟な評価が必要です。"
85,Data Cloudにデータを取り込む際、データレイクオブジェクト（DLO）からデータモデルオブジェクト（DMO）へデータをマッピングします。このプロセスにおいて、DMO間のリレーションシップを定義するためにDLO項目をマッピングする場合、どのような種類のDMO項目に対してマッピングを行いますか？,主キー項目,テキスト項目,参照項目,日付時刻項目,C,"A. 主キー項目 - 主キー項目は、DMO内の各レコードを一意に識別するために使用されます。リレーションシップを定義する際に参照される側（親オブジェクト側など）のキーとして重要ですが、リレーションシップ自体を定義するためにDLOからマッピングされるのは通常、参照項目です。

B. テキスト項目 - テキスト項目は、文字列データを格納するために使用されます。DLOからDMOへテキストデータをマッピングすることは一般的ですが、DMO間のリレーションシップを定義する項目としては通常、参照項目が用いられます。

C. 参照項目 - 正解です。DMO間のリレーションシップを定義する場合、一方のDMO（子オブジェクト側など）に参照項目を作成し、その項目に対して、関連するもう一方のDMO（親オブジェクト側など）のレコードを識別する値（通常は主キー値や外部ID）を持つDLO項目をマッピングします。これにより、2つのDMOレコード間の関連付けが行われます。

D. 日付時刻項目 - 日付時刻項目は、日付や時刻の情報を格納するために使用されます。DMO間のリレーションシップを定義する目的で直接使用される項目ではありません。"
86,Data Cloudにおいて、プライバシーとコンプライアンスを遵守するために、個人のデータ主体からの削除要求やアクセス要求に対応するプロセスを管理する機能は何ですか？,データマスキング,データ主体権利 (DSR) 管理,データストリームのフィルタリング,セグメントの除外ルール,B,"A. データマスキング - データマスキングは、機密データを保護するために、元のデータを意味のない文字や別の値に置き換える技術です。データ主体からの要求に直接対応するプロセス管理機能ではありません。

B. データ主体権利 (DSR) 管理 - 正解です。Data Cloudは、GDPRやCCPAなどのプライバシー規制に対応するため、データ主体（個人）からの自身のデータに対するアクセス要求や削除要求（忘れられる権利）などを管理し、実行するための機能を提供しています。これはデータ主体権利（DSR）管理の一部として扱われます。

C. データストリームのフィルタリング - データストリームのフィルタリングは、Data Cloudに取り込むデータを特定の条件に基づいて選択または除外する機能です。既存のデータに対する削除要求やアクセス要求を管理するものではありません。

D. セグメントの除外ルール - セグメントの除外ルールは、特定の条件に基づいてセグメントから個人を除外するために使用されます。データ主体からの全体的なデータ削除要求やアクセス要求に対応するプロセス管理とは異なります。"
87,あるマーケティングチームは、複数のデータソース（ウェブサイト、モバイルアプリ、CRM）から収集した顧客行動データをData Cloudに取り込んでいます。これらのデータソース間で共通の識別子が存在しない場合、異なるソースからの同一顧客のレコードを関連付けるために、Data Cloudで最初に設定すべき重要な要素は何ですか？,データストリーム,ID解決ルールセット,セグメンテーション,アクティベーション,B,"A. データストリーム - データストリームは、Data Cloudにデータを取り込むためのパイプラインです。データソースへの接続、データの取り込みスケジュール、および初期のデータ変換を定義しますが、異なるソース間のレコードの関連付け自体を主目的とはしていません。

B. ID解決ルールセット - 正解です。ID解決ルールセットは、異なるデータソースからのレコードを照合し、統合プロファイル（単一の顧客ビュー）を作成するためのルールを定義します。共通の識別子がない場合でも、ファーストネーム、ラストネーム、メールアドレス、電話番号などの属性に基づいてレコードを一致させるルールを設定できます。これが、異なるソースからの同一顧客を関連付けるための中心的なプロセスです。

C. セグメンテーション - セグメンテーションは、統合された顧客プロファイルに基づいて、特定の条件に合致する顧客グループを作成するプロセスです。これはID解決によって顧客データが統合された後に行われるステップであり、レコードの関連付け自体を行うものではありません。

D. アクティベーション - アクティベーションは、Data Cloudで作成されたセグメントやインサイトを、マーケティングキャンペーンやパーソナライゼーションなどの外部システムで利用可能にするプロセスです。これもID解決とセグメンテーションの後続のステップとなります。"
88,Data Cloudに様々なソースからデータを取り込む際、データの構造と意味を標準化し、一貫性のある分析やセグメンテーションを可能にするための基礎となる要素は何ですか？,データモデルオブジェクト (DMO),データストリーム,ID解決ルールセット,アクティベーションターゲット,A,"A. データモデルオブジェクト (DMO) - 正解です。データモデルオブジェクトは、Data Cloudに取り込まれたデータの構造（項目、データ型、関係）を定義し、標準化するためのスキーマ定義です。これにより、異なるソースからのデータが一貫した形式で扱われ、分析やセグメンテーションの基盤となります。

B. データストリーム - データストリームは、外部のデータソースからData Cloudへデータを継続的に取り込むための接続と設定を定義します。データの取り込みプロセスには関わりますが、データの構造を標準化する要素そのものではありません。

C. ID解決ルールセット - ID解決ルールセットは、異なるデータソースから取り込まれた同一人物に関連するレコードを照合し、統合された顧客プロファイルを作成するためのルールを定義します。データの統合には不可欠ですが、データの構造そのものを定義するものではありません。

D. アクティベーションターゲット - アクティベーションターゲットは、Data Cloudで作成されたセグメントやインサイトを出力し、利用可能にする外部システム（例: マーケティングプラットフォーム、広告チャネル）の設定を指します。データの活用先を定義するものであり、データの構造定義とは異なります。"
89,マーケティング担当者は、Data Cloudを利用して特定の顧客グループにターゲットを絞ったキャンペーンを実施したいと考えています。この目的を達成するためにData Cloudで利用できる主要な機能や概念はどれですか？（2つ選択）,データストリーム,セグメンテーション,計算済みインサイト,ID解決ルールセット,"B,C","A. データストリーム - データストリームは、外部ソースからData Cloudへデータを継続的に取り込むための設定です。キャンペーンのターゲットとなる顧客グループを作成する直接的な機能ではありません。

B. セグメンテーション - 正解です。セグメンテーションは、Data Cloud内の統合されたデータに基づき、特定の属性や行動パターンを持つ顧客グループ（セグメント）を作成するための中心的な機能です。これにより、ターゲットを絞ったキャンペーンの対象者リストを作成できます。

C. 計算済みインサイト - 正解です。計算済みインサイトは、Data Cloud内のデータから顧客生涯価値（LTV）、エンゲージメントスコア、購入頻度などの指標を計算する機能です。これらのインサイトは、セグメントを作成する際の条件として利用でき、より精緻なターゲティングを可能にします。

D. ID解決ルールセット - ID解決ルールセットは、異なるソースからの顧客データを照合し、統一されたプロファイルを作成するためのルールです。セグメンテーションの前提となるデータの質を高めますが、セグメント作成そのものの機能ではありません。"
90,Data Cloudで特定された高価値顧客セグメントの情報を、Sales Cloudの営業担当者が参照できるようにし、さらにMarketing Cloudでパーソナライズされたメールを送信したいと考えています。このデータ活用を実現するためにData Cloudで設定する主要な機能はどれですか？（2つ選択）,アクティベーションの設定,データストリームの作成,データアクションの作成,ID解決ルールセットの調整,"A,C","A. アクティベーションの設定 - 正解です。アクティベーションは、Data Cloudで作成したセグメントやインサイトを、Marketing Cloud Engagementなどの外部システム（アクティベーションターゲット）に送信し、キャンペーンなどで利用可能にするための機能です。パーソナライズされたメール送信の要件に対応します。

B. データストリームの作成 - データストリームは、外部ソースからData Cloudへデータを取り込むための設定です。Data Cloud内のデータを活用する段階ではなく、その前段階のプロセスに関わります。

C. データアクションの作成 - 正解です。データアクションを使用すると、Data Cloudのイベント（例: 特定セグメントへの個人の追加、計算済みインサイトの閾値到達など）をトリガーとして、Salesforce PlatformのフローやApexなどを呼び出すことができます。これにより、Sales Cloud上で営業担当者向けのToDoを作成したり、関連レコードを更新したりといった活用が可能になります。

D. ID解決ルールセットの調整 - ID解決ルールセットは、異なるデータソースからの顧客情報を統合し、単一の顧客プロファイルを作成するためのルール設定です。データの質を高める上で重要ですが、作成されたデータを外部システムで活用するための直接的な設定ではありません。"
91,企業が様々なチャネルやシステムに散在する顧客データを統合し、顧客一人ひとりに対する理解を深め、パーソナライズされた体験を提供することを目指しています。この目標達成のためにData Cloudが提供する最も中心的な価値は何ですか？,リアルタイムでのデータストリーミング処理能力,高度な機械学習モデルの容易な構築環境,大量の生データを保管するストレージ機能,統合された単一の顧客ビューの提供,D,"A. リアルタイムでのデータストリーミング処理能力 - Data Cloudはリアルタイムに近いデータ処理能力を持ちますが、これは統合された顧客ビューを実現するための手段の一つであり、プラットフォームの中心的な価値そのものではありません。

B. 高度な機械学習モデルの容易な構築環境 - Data CloudはEinsteinなどのAI/ML機能と連携できますが、Data Cloud自体が主として機械学習モデルの構築環境を提供するわけではなく、その中心的な価値はデータ統合と活用基盤の提供にあります。

C. 大量の生データを保管するストレージ機能 - Data Cloudは大量のデータを扱うことができますが、単なるデータ保管庫（データウェアハウス）ではなく、データを統合し、意味のあるインサイトを引き出し、活用することに主眼が置かれた顧客データプラットフォーム（CDP）としての側面が中心的な価値です。

D. 統合された単一の顧客ビューの提供 - 正解です。Data Cloudの最も中心的な価値は、様々なソースから収集した断片的な顧客データを統合・調整し、顧客一人ひとりに関する信頼性の高い包括的なプロファイル（単一の顧客ビュー、カスタマー360）を構築することです。これがパーソナライズされた体験を提供する上での基盤となります。"
92,Data Cloudへのデータ取り込みプロセス中に、メールアドレス項目に不正な形式のデータが多数含まれていることが判明しました。このようなデータ品質の問題に対処し、後続のID解決やセグメンテーションの精度を高めるために、管理者がData Cloudで検討すべきアクションは何ですか？,データストリームの数式項目やデータ変換機能を用いて、取り込み時にデータを整形または標準化する。,ID解決のマッチングルールを調整して、より多くのレコードが一致するようにする。,データ取り込み元のソースシステム担当者にデータ修正を依頼する。,品質が低いデータを含むデータストリームの取り込みを停止する。,A,"A. データストリームの数式項目やデータ変換機能を用いて、取り込み時にデータを整形または標準化する。 - 正解です。Data Cloudのデータストリームでは、数式項目やライブラリ化されたデータ変換機能を利用できます。これらを使って、取り込みデータに対してクレンジング（例: メールアドレス形式の検証・修正、不要なスペースの除去）や標準化（例: 大文字・小文字の統一）を適用し、データ品質を向上させることが可能です。

B. ID解決のマッチングルールを調整して、より多くのレコードが一致するようにする。 - マッチングルールを不必要に緩めると、本来異なる人物のレコードが誤って統合されてしまうリスクが高まり、データ品質やID解決の精度を低下させる可能性があります。データ品質の問題がある場合は、まずデータのクレンジングを検討すべきです。

C. データ取り込み元のソースシステム担当者にデータ修正を依頼する。 - データ品質問題の根本的な解決のためには、発生源であるソースシステムでのデータ修正や入力プロセスの改善が理想的です。しかし、これはData Cloudプラットフォーム内での直接的なアクションではなく、外部との連携が必要となります。Data Cloud内で可能な対処策も検討すべきです。

D. 品質が低いデータを含むデータストリームの取り込みを停止する。 - データストリームの取り込みを完全に停止することは、データ活用機会の損失につながる可能性があります。データ品質の問題に対処する他の方法（クレンジング、変換など）を検討した上での最終手段となるべきです。"
93,Data CloudでID解決ルールセットを実行した後、管理者はルールがどの程度正確に顧客プロファイルを統合できているか、また、潜在的な統合の問題（例えば、異なる人物が誤って統合されている可能性）がないかを確認したいと考えています。この目的のために参照すべきData Cloudの機能またはレポートは何ですか？,データストリームの詳細ログ,セグメントの重複チェック機能,アクティベーションターゲットへの送信履歴,ID解決ジョブの概要と重複分析レポート,D,"A. データストリームの詳細ログ - データストリームのログは、データの取り込みプロセス（成功、失敗、処理されたレコード数など）に関する情報を提供しますが、ID解決ルールがどのように適用され、どの程度正確にプロファイルが統合されたかを評価するための直接的な情報は含まれていません。

B. セグメントの重複チェック機能 - セグメント作成プロセスには重複排除のロジックが含まれる場合がありますが、これはセグメント固有のものであり、ID解決プロセス全体の精度や品質を体系的に評価するための主要な手段ではありません。

C. アクティベーションターゲットへの送信履歴 - アクティベーションの履歴は、Data Cloudから外部システムへどのセグメントやデータがいつ送信されたかを示す記録です。ID解決の精度、つまりプロファイルの統合がどれだけ正確に行われたかを評価する情報ではありません。

D. ID解決ジョブの概要と重複分析レポート - 正解です。ID解決ジョブの実行結果には、処理されたソースプロファイルの数、作成または更新された統合プロファイルの数、一致ルールによって識別された潜在的な重複レコードの数などの概要情報が含まれます。これらの情報や関連する分析レポートを確認することで、ID解決の有効性や潜在的な問題を把握し、精度を評価するのに役立ちます。"
94,あるグローバル小売企業は、複数のオンラインストア、実店舗、および顧客ロイヤルティプログラムからの顧客データをSalesforce Data Cloudに統合したいと考えています。この企業がデータ統合プロセスを開始するために最初に実行すべき手順は何でしょうか？,Data Cloud内で包括的なマッチングルールと調整ルールを設計および実装する。,各データソースからData Cloudのデータレイクオブジェクトに直接データを一括ロードする。,Data Cloudでデータストリームを作成し、各データソースへの接続を確立する。,統合された顧客プロファイルのセグメント化戦略を定義し、関連するセグメントを作成する。,C,"A. Data Cloud内で包括的なマッチングルールと調整ルールを設計および実装する - マッチングルールと調整ルールは、データがData Cloudに取り込まれた後に、重複するレコードを特定し、異なるソースからの情報を統合するために使用されます。データソースへの接続を確立する前にこれらのルールを定義することは、データ統合プロセスの最初のステップではありません。

B. 各データソースからData Cloudのデータレイクオブジェクトに直接データを一括ロードする - データを直接データレイクオブジェクトにロードすることも可能ですが、通常はデータストリームを通じて行われます。データストリームは、継続的なデータフローを可能にし、データの取り込みと変換を管理するためのより柔軟な方法を提供します。

C. Data Cloudでデータストリームを作成し、各データソースへの接続を確立する - 正解です。データ統合プロセスの最初のステップは、データが存在するさまざまなソース（オンラインストア、実店舗システム、ロイヤルティプログラムなど）をData Cloudに接続することです。これは、Data Cloudでデータストリームを作成し、各データソースとの接続を設定することによって行われます。

D. 統合された顧客プロファイルのセグメント化戦略を定義し、関連するセグメントを作成する - セグメント化は、統合された顧客データに基づいて特定のグループを作成するプロセスです。これは、データがData Cloudに取り込まれ、統合された後に実行される手順であり、データ統合プロセスの最初のステップではありません。"
95,Universal Containersは、Salesforce Data Cloudを使用して、Webサイトの行動データ、メールエンゲージメントデータ、およびCRMデータを統合し、顧客のエンゲージメントジャーニー全体を把握したいと考えています。この統合されたデータセット内で、特定の顧客の一意性を保証し、異なるデータソースからの関連するインタラクションをリンクするために使用される主要な概念は何でしょうか？,データソースコネクタ,識別子,データ変換関数,セグメント化ルール,B,"A. データソースコネクタ - データソースコネクタは、Salesforce Data Cloudがさまざまなシステムやプラットフォームからデータを取得するために使用するメカニズムです。これらはデータの取り込みを可能にしますが、個々の顧客の一意性を保証するものではありません。

B. 識別子 - 正解です。識別子は、Salesforce Data Cloud内で個々の顧客を特定し、異なるデータソースからの関連するデータをリンクするために使用される属性または属性の組み合わせです。共通の識別子（メールアドレス、顧客IDなど）を使用することで、システムは同じ顧客からの異なるインタラクションを正確に関連付けることができます。

C. データ変換関数 - データ変換関数は、データがData Cloudに取り込まれる際に、その形式や構造を標準化するために使用されます。これらはデータの品質と一貫性を向上させるのに役立ちますが、個々の顧客の一意性を直接保証するものではありません。

D. セグメント化ルール - セグメント化ルールは、統合されたデータに基づいて特定の顧客グループを作成するために使用されます。これらは顧客を特性や行動に基づいて分類するために使用されますが、個々の顧客の一意性を保証したり、異なるデータソースからのインタラクションをリンクしたりする主要なメカニズムではありません。"
96,ある金融サービス会社は、顧客の取引履歴、マーケティングインタラクション、およびサービスケースのデータをSalesforce Data Cloudに取り込み、顧客の全体像を把握したいと考えています。これらの多様なデータセットを保存し、後続のデータ処理と分析のために一元化されたリポジトリを提供するData Cloudの機能は何でしょうか？,データソースコネクタ,データ変換,データレイクオブジェクト,マッチングルール,C,"A. データソースコネクタ - データソースコネクタは、Data Cloudがさまざまな外部システムからデータを抽出するために使用するツールです。これらはデータの取り込みを可能にしますが、データの保存場所を提供するわけではありません。

B. データ変換 - データ変換は、Data Cloudに取り込まれたデータをクレンジング、標準化、および整形するプロセスです。これはデータの品質を向上させるために重要ですが、データの主要な保存場所ではありません。

C. データレイクオブジェクト - 正解です。データレイクオブジェクトは、Salesforce Data Cloud内の主要なデータリポジトリであり、さまざまなソースからの大量の構造化データおよび非構造化データを保存するために設計されています。これにより、組織は統合されたビューでデータを分析できます。

D. マッチングルール - マッチングルールは、Data Cloud内で重複する顧客プロファイルを特定し、統合するために使用されます。これはデータの統合に不可欠ですが、データの保存を担当する機能ではありません。"
97,Universal Containersは、自社のWebサイトのクリックストリームデータをSalesforce Data Cloudにリアルタイムで取り込み、顧客の行動を即座に分析したいと考えています。この要件を満たすために、最初に設定する必要があるData Cloudのコンポーネントは何でしょうか？,プロファイル統合ルール,データレイクオブジェクト,データストリーム,調整ルール,C,"A. プロファイル統合ルール - プロファイル統合ルールは、異なるデータソースからの顧客プロファイルを統合し、単一の顧客ビューを作成するために使用されます。これはデータの取り込み後に行われる処理です。

B. データレイクオブジェクト - データレイクオブジェクトは、Data Cloudに取り込まれたデータを保存するためのリポジトリです。データを取り込む前にデータレイクオブジェクトが存在する必要がありますが、データ取り込みの最初の設定ステップではありません。

C. データストリーム - 正解です。データストリームは、Salesforce Data Cloudへのデータの継続的な流れを設定するために使用されます。リアルタイムでデータを外部ソースから取り込むためには、まずそのデータソースへのデータストリームを作成する必要があります。

D. 調整ルール - 調整ルールは、マッチングされたプロファイル間の競合する属性値を解決するために使用されます。これはデータの統合段階で行われる処理であり、データの取り込みの最初のステップではありません。"
98,ある小売業者は、オンラインストアと実店舗の顧客データをSalesforce Data Cloudに統合しています。データ統合プロセスの重要なステップとして、システムは同一人物を表す可能性のある複数の顧客レコードを特定し、それらを単一の統合された顧客プロファイルにまとめる必要があります。この目的を達成するためにData Cloudで使用される主要な機能は何でしょうか？,データ変換ルール,マッチングルール,セグメント化ルール,データストリーム,B,"A. データ変換ルール - データ変換ルールは、データがData Cloudに取り込まれる際に、その形式や構造を標準化するために使用されます。これはデータの品質を向上させるのに役立ちますが、重複レコードの特定と統合を行う機能ではありません。

B. マッチングルール - 正解です。マッチングルールは、Salesforce Data Cloud内で、異なるデータソースに存在する可能性のある同一のエンティティ（この場合は顧客）のレコードを特定するために使用されます。定義された一致条件に基づいて、システムは重複するレコードを特定し、統合の候補としてフラグを立てます。

C. セグメント化ルール - セグメント化ルールは、統合されたデータに基づいて特定の顧客グループを作成するために使用されます。これは、顧客を特性や行動に基づいて分類するために使用されますが、重複レコードの特定や統合を行う機能ではありません。

D. データストリーム - データストリームは、Salesforce Data Cloudへのデータの継続的な流れを設定するために使用されます。これはデータの取り込みを可能にするメカニズムですが、データの重複を特定したり統合したりする機能ではありません。"
99,Salesforce Data Cloudにおけるアイデンティティ解決の主な目的として、正しいものを2つ選択してください。,データソースからData Cloudへのデータ取り込みを自動化する。,異なるデータソースに存在する可能性のある同一人物のレコードを特定し、統合する。,統合された顧客プロファイルのデータ品質を向上させる。,顧客データをリアルタイムで可視化するためのダッシュボードを作成する。,"B,C","A. データソースからData Cloudへのデータ取り込みを自動化する - これはデータストリームの主な機能であり、アイデンティティ解決の直接的な目的ではありません。データストリームはデータの流れを管理しますが、個々の顧客レコードの識別と統合は行いません。

B. 異なるデータソースに存在する可能性のある同一人物のレコードを特定し、統合する - 正解です。アイデンティティ解決の主要な目的の一つは、様々なデータソースからの顧客データを照合し、同一人物のレコードを特定して単一の統合されたプロファイルを作成することです。これにより、顧客の全体像を把握することが可能になります。

C. 統合された顧客プロファイルのデータ品質を向上させる - 正解です。アイデンティティ解決のプロセスでは、重複するレコードを統合するだけでなく、異なるソースからの情報を組み合わせることで、より完全で正確な顧客プロファイルを作成し、データ品質を向上させることができます。

D. 顧客データをリアルタイムで可視化するためのダッシュボードを作成する - ダッシュボードの作成は、Data Cloudで統合されたデータを活用する方法の一つですが、アイデンティティ解決の直接的な目的ではありません。アイデンティティ解決によって統合されたデータは、ダッシュボードやレポートの基礎となります。"
100,Salesforce Data Cloudでデータを効率的に取り込み、分析に適した形式に準備するために考慮すべき主要な要素を2つ選択してください。,データソースのAPI制限を理解し、適切な取り込み頻度を設定する。,データレイクオブジェクトのスキーマを、取り込むすべてのソースデータに対応できるように設計する。,取り込むデータの量に基づいて、最適な数のプロファイル統合ルールを作成する。,取り込むデータの品質を評価し、必要に応じてデータ変換プロセスを設計する。,"A,D","A. データソースのAPI制限を理解し、適切な取り込み頻度を設定する - 正解です。外部システムからデータをData Cloudに取り込む際、多くの場合APIを介して行われます。各APIには通常、呼び出し回数やデータ量に関する制限があるため、これらの制限を理解し、適切な取り込み頻度を設定することは、効率的かつ安定したデータ取り込みのために重要です。

B. データレイクオブジェクトのスキーマを、取り込むすべてのソースデータに対応できるように設計する - データレイクオブジェクトのスキーマは、柔軟性を持たせるべきですが、「すべての」ソースデータに厳密に対応させる必要はありません。分析の要件やデータの種類に応じて、適切なスキーマ設計を行うことが重要です。

C. 取り込むデータの量に基づいて、最適な数のプロファイル統合ルールを作成する - プロファイル統合ルールの数は、データの量よりも、統合の複雑さや必要な精度に依存します。データ量が多いからといって、単純に統合ルールを増やすことが最適とは限りません。

D. 取り込むデータの品質を評価し、必要に応じてデータ変換プロセスを設計する - 正解です。取り込むデータの品質は、その後の分析結果に大きな影響を与えます。データの欠損、不整合、誤りなどを特定し、必要に応じてクレンジング、標準化、変換などのデータ変換プロセスを設計することは、高品質なデータ分析のために不可欠です。"
